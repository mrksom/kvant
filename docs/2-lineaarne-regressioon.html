<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Peatükk 2 Lineaarne regressioon | Kvantitatiivne andmeanalüüs</title>
  <meta name="description" content="Peatükk 2 Lineaarne regressioon | Kvantitatiivne andmeanalüüs" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Peatükk 2 Lineaarne regressioon | Kvantitatiivne andmeanalüüs" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Peatükk 2 Lineaarne regressioon | Kvantitatiivne andmeanalüüs" />
  
  
  

<meta name="author" content="Marko Sõmer" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="1-sissejuhatus-r-i.html"/>
<link rel="next" href="3-logistiline-regressioon.html"/>
<script src="assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="assets/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="assets/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="assets/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="assets/tabwid-1.1.0/tabwid.css" rel="stylesheet" />
<link href="assets/tabwid-1.1.0/scrool.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="custom/custom_styles.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='before'><a href="./">Kvant</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Alustuseks</a></li>
<li class="part"><span><b>I Meeldetuletus</b></span></li>
<li class="chapter" data-level="1" data-path="1-sissejuhatus-r-i.html"><a href="1-sissejuhatus-r-i.html"><i class="fa fa-check"></i><b>1</b> Sissejuhatus R-i</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1-sissejuhatus-r-i.html"><a href="1-sissejuhatus-r-i.html#päris-algus"><i class="fa fa-check"></i><b>1.1</b> Päris algus</a></li>
<li class="chapter" data-level="1.2" data-path="1-sissejuhatus-r-i.html"><a href="1-sissejuhatus-r-i.html#andmetega-töötamine"><i class="fa fa-check"></i><b>1.2</b> Andmetega töötamine</a></li>
<li class="chapter" data-level="1.3" data-path="1-sissejuhatus-r-i.html"><a href="1-sissejuhatus-r-i.html#r-markdown"><i class="fa fa-check"></i><b>1.3</b> R markdown</a></li>
<li class="chapter" data-level="1.4" data-path="1-sissejuhatus-r-i.html"><a href="1-sissejuhatus-r-i.html#andmegraafika"><i class="fa fa-check"></i><b>1.4</b> Andmegraafika</a></li>
<li class="chapter" data-level="1.5" data-path="1-sissejuhatus-r-i.html"><a href="1-sissejuhatus-r-i.html#edasiseks-lugemiseks"><i class="fa fa-check"></i><b>1.5</b> Edasiseks lugemiseks</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html"><i class="fa fa-check"></i><b>2</b> Lineaarne regressioon</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#lihtne-lineaarne-regressioon"><i class="fa fa-check"></i><b>2.1</b> Lihtne lineaarne regressioon</a></li>
<li class="chapter" data-level="2.2" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#regressioon-r-is"><i class="fa fa-check"></i><b>2.2</b> Regressioon R-is</a></li>
<li class="chapter" data-level="2.3" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#regressiooni-jäägid"><i class="fa fa-check"></i><b>2.3</b> Regressiooni jäägid</a></li>
<li class="chapter" data-level="2.4" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#regressioonimudeli-sobitumine"><i class="fa fa-check"></i><b>2.4</b> Regressioonimudeli sobitumine</a></li>
<li class="chapter" data-level="2.5" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#kategoriaalsed-tunnused-regressioonis"><i class="fa fa-check"></i><b>2.5</b> Kategoriaalsed tunnused regressioonis</a></li>
<li class="chapter" data-level="2.6" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#mitmene-regressioon"><i class="fa fa-check"></i><b>2.6</b> Mitmene regressioon</a></li>
<li class="chapter" data-level="2.7" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#koosmõjud"><i class="fa fa-check"></i><b>2.7</b> Koosmõjud</a></li>
<li class="chapter" data-level="2.8" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#mudelite-võrdlemine"><i class="fa fa-check"></i><b>2.8</b> Mudelite võrdlemine</a></li>
<li class="chapter" data-level="2.9" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#regressioonimudeli-eeldused"><i class="fa fa-check"></i><b>2.9</b> Regressioonimudeli eeldused</a></li>
<li class="chapter" data-level="2.10" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#kuidas-eelduste-täidetust-hinnata"><i class="fa fa-check"></i><b>2.10</b> Kuidas eelduste täidetust hinnata?</a></li>
<li class="chapter" data-level="2.11" data-path="2-lineaarne-regressioon.html"><a href="2-lineaarne-regressioon.html#tunnuste-transformatsioonid"><i class="fa fa-check"></i><b>2.11</b> Tunnuste transformatsioonid</a></li>
</ul></li>
<li class="part"><span><b>II Üldistatud lineaarsed mudelid</b></span></li>
<li class="chapter" data-level="3" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html"><i class="fa fa-check"></i><b>3</b> Logistiline regressioon</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#šansid"><i class="fa fa-check"></i><b>3.1</b> Šansid</a></li>
<li class="chapter" data-level="3.2" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#logit"><i class="fa fa-check"></i><b>3.2</b> Logit</a></li>
<li class="chapter" data-level="3.3" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#logit-mudel"><i class="fa fa-check"></i><b>3.3</b> Logit mudel</a></li>
<li class="chapter" data-level="3.4" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#mudeli-tõlgendus"><i class="fa fa-check"></i><b>3.4</b> Mudeli tõlgendus</a></li>
<li class="chapter" data-level="3.5" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#logistiline-regressioon-r-is"><i class="fa fa-check"></i><b>3.5</b> Logistiline regressioon R-is</a></li>
<li class="chapter" data-level="3.6" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#mudeli-kvaliteet"><i class="fa fa-check"></i><b>3.6</b> Mudeli kvaliteet</a></li>
<li class="chapter" data-level="3.7" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#predict"><i class="fa fa-check"></i><b>3.7</b> Predict</a></li>
<li class="chapter" data-level="3.8" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#marginaalsed-efektid"><i class="fa fa-check"></i><b>3.8</b> Marginaalsed efektid</a></li>
<li class="chapter" data-level="3.9" data-path="3-logistiline-regressioon.html"><a href="3-logistiline-regressioon.html#prognoosi-täpsus"><i class="fa fa-check"></i><b>3.9</b> Prognoosi täpsus</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-poissoni-regressioon.html"><a href="4-poissoni-regressioon.html"><i class="fa fa-check"></i><b>4</b> Poissoni regressioon</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4-poissoni-regressioon.html"><a href="4-poissoni-regressioon.html#mudeli-tõlgendus-1"><i class="fa fa-check"></i><b>4.1</b> Mudeli tõlgendus</a></li>
<li class="chapter" data-level="4.2" data-path="4-poissoni-regressioon.html"><a href="4-poissoni-regressioon.html#poissoni-regressiooni-eeldused"><i class="fa fa-check"></i><b>4.2</b> Poissoni regressiooni eeldused</a></li>
<li class="chapter" data-level="4.3" data-path="4-poissoni-regressioon.html"><a href="4-poissoni-regressioon.html#mudeli-hindamine-r-is"><i class="fa fa-check"></i><b>4.3</b> Mudeli hindamine R-is</a></li>
<li class="chapter" data-level="4.4" data-path="4-poissoni-regressioon.html"><a href="4-poissoni-regressioon.html#mudeli-eelduste-kontroll"><i class="fa fa-check"></i><b>4.4</b> Mudeli eelduste kontroll</a></li>
<li class="chapter" data-level="4.5" data-path="4-poissoni-regressioon.html"><a href="4-poissoni-regressioon.html#mudeli-sobivus-model-fit"><i class="fa fa-check"></i><b>4.5</b> Mudeli sobivus (<em>model fit</em>)</a></li>
</ul></li>
<li class="part"><span><b>III Mitmetasandiline regressioon</b></span></li>
<li class="chapter" data-level="5" data-path="5-mitmetasandiline-regressioon.html"><a href="5-mitmetasandiline-regressioon.html"><i class="fa fa-check"></i><b>5</b> Mitmetasandiline regressioon</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-mitmetasandiline-regressioon.html"><a href="5-mitmetasandiline-regressioon.html#andmete-hierarhiline-struktuur"><i class="fa fa-check"></i><b>5.1</b> Andmete hierarhiline struktuur</a></li>
<li class="chapter" data-level="5.2" data-path="5-mitmetasandiline-regressioon.html"><a href="5-mitmetasandiline-regressioon.html#mitmetasandiline-analüüs"><i class="fa fa-check"></i><b>5.2</b> Mitmetasandiline analüüs</a></li>
<li class="chapter" data-level="5.3" data-path="5-mitmetasandiline-regressioon.html"><a href="5-mitmetasandiline-regressioon.html#mitmetasandilise-analüüsi-eeldused"><i class="fa fa-check"></i><b>5.3</b> Mitmetasandilise analüüsi eeldused</a></li>
<li class="chapter" data-level="5.4" data-path="5-mitmetasandiline-regressioon.html"><a href="5-mitmetasandiline-regressioon.html#mitemtasandiline-analüüs-ris"><i class="fa fa-check"></i><b>5.4</b> Mitemtasandiline analüüs Ris</a></li>
</ul></li>
<li class="part"><span><b>IV Valimiuuringud</b></span></li>
<li class="chapter" data-level="6" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html"><i class="fa fa-check"></i><b>6</b> Valimiuuringud</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#tõenäosuslik-valim-probability-sample"><i class="fa fa-check"></i><b>6.1</b> Tõenäosuslik valim (probability sample)</a></li>
<li class="chapter" data-level="6.2" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#kaalud"><i class="fa fa-check"></i><b>6.2</b> Kaalud</a></li>
<li class="chapter" data-level="6.3" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#valimidisain"><i class="fa fa-check"></i><b>6.3</b> Valimidisain</a></li>
<li class="chapter" data-level="6.4" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#tulemuste-valimidisaini-suhtes-korrigeerimine"><i class="fa fa-check"></i><b>6.4</b> Tulemuste valimidisaini suhtes korrigeerimine</a></li>
<li class="chapter" data-level="6.5" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#küsitlusandmed-ris"><i class="fa fa-check"></i><b>6.5</b> Küsitlusandmed Ris</a></li>
<li class="chapter" data-level="6.6" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#valimiandmete-analüüs"><i class="fa fa-check"></i><b>6.6</b> Valimiandmete analüüs</a></li>
<li class="chapter" data-level="6.7" data-path="6-valimiuuringud.html"><a href="6-valimiuuringud.html#plausible-values"><i class="fa fa-check"></i><b>6.7</b> Plausible values</a></li>
</ul></li>
<li class="part"><span><b>V SEM</b></span></li>
<li class="chapter" data-level="7" data-path="7-struktuurivõrrandite-mudelid.html"><a href="7-struktuurivõrrandite-mudelid.html"><i class="fa fa-check"></i><b>7</b> Struktuurivõrrandite mudelid</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7-struktuurivõrrandite-mudelid.html"><a href="7-struktuurivõrrandite-mudelid.html#rajaanalüüs"><i class="fa fa-check"></i><b>7.1</b> Rajaanalüüs</a></li>
<li class="chapter" data-level="7.2" data-path="7-struktuurivõrrandite-mudelid.html"><a href="7-struktuurivõrrandite-mudelid.html#faktoranalüüs"><i class="fa fa-check"></i><b>7.2</b> Faktoranalüüs</a></li>
<li class="chapter" data-level="7.3" data-path="7-struktuurivõrrandite-mudelid.html"><a href="7-struktuurivõrrandite-mudelid.html#sruktuurivõrrandite-mudelid"><i class="fa fa-check"></i><b>7.3</b> Sruktuurivõrrandite mudelid</a></li>
<li class="chapter" data-level="7.4" data-path="7-struktuurivõrrandite-mudelid.html"><a href="7-struktuurivõrrandite-mudelid.html#struktuurivõrrandite-mudelid-ris"><i class="fa fa-check"></i><b>7.4</b> Struktuurivõrrandite mudelid Ris</a></li>
</ul></li>
<li class="part"><span><b>VI Klasteranalüüs</b></span></li>
<li class="chapter" data-level="8" data-path="8-klasteranalüüs.html"><a href="8-klasteranalüüs.html"><i class="fa fa-check"></i><b>8</b> Klasteranalüüs</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8-klasteranalüüs.html"><a href="8-klasteranalüüs.html#mis-see-klasteranalüüs-on"><i class="fa fa-check"></i><b>8.1</b> Mis see klasteranalüüs on?</a></li>
<li class="chapter" data-level="8.2" data-path="8-klasteranalüüs.html"><a href="8-klasteranalüüs.html#hierarhiline-klasteranalüüs"><i class="fa fa-check"></i><b>8.2</b> Hierarhiline klasteranalüüs</a></li>
<li class="chapter" data-level="8.3" data-path="8-klasteranalüüs.html"><a href="8-klasteranalüüs.html#k-keskmiste-k-means-klasterdamine"><i class="fa fa-check"></i><b>8.3</b> K-keskmiste (k-means) klasterdamine</a></li>
<li class="chapter" data-level="8.4" data-path="8-klasteranalüüs.html"><a href="8-klasteranalüüs.html#klasteranalüüsi-tulemi-valiidsus"><i class="fa fa-check"></i><b>8.4</b> Klasteranalüüsi tulemi valiidsus</a></li>
</ul></li>
<li class="appendix"><span><b>LISA</b></span></li>
<li class="chapter" data-level="A" data-path="A-tavaline-lineaarne-regressioon-maatriksarvutusena.html"><a href="A-tavaline-lineaarne-regressioon-maatriksarvutusena.html"><i class="fa fa-check"></i><b>A</b> Tavaline lineaarne regressioon maatriksarvutusena</a></li>
<li class="chapter" data-level="B" data-path="B-delta-meetod.html"><a href="B-delta-meetod.html"><i class="fa fa-check"></i><b>B</b> Delta meetod</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Kvantitatiivne andmeanalüüs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lineaarne-regressioon" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Peatükk 2</span> Lineaarne regressioon<a href="2-lineaarne-regressioon.html#lineaarne-regressioon" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="lihtne-lineaarne-regressioon" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Lihtne lineaarne regressioon<a href="2-lineaarne-regressioon.html#lihtne-lineaarne-regressioon" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Lihtne lineaarne regressioon (<em>simple linear regression</em>) on statistiline meetod mis võimaldab hinnata ja kvantifitseerida kahe arvtunnuse vahelist suhet. Regressioonisuhte puhul eeldatakse, et üks tunnustest oleks nn sõltuv tunnus ja teine sõltumatu<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, kus sõltuva tunnuse väärtus on mõjutatud (sõltub) sõltumatu tunnuse väärtusest. Kui sõltumatuid tunnuseid on rohkem kui üks, on tegemist mitmese regressiooniga (sellest hiljem), ühe sõltumatu tunnuse korral nimetatakse mudelit nn “lihtsaks” regressiooniks (<em>simple linear regression</em>). Keskendume esialgu sellele “lihtsale” variandile.</p>
<p>Kasutame näitena Piaaci andmestikku. Tõmbame andmestiku sisse ja uurime graafiliselt sissetuleku (<em>sissetulek</em>) ning matemaatilise kirjaokuse (<em>numeracy</em>) vahelist seost.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="2-lineaarne-regressioon.html#cb401-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loeme kõigepealt sisse vajalikud paketid</span></span>
<span id="cb401-2"><a href="2-lineaarne-regressioon.html#cb401-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb401-3"><a href="2-lineaarne-regressioon.html#cb401-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb401-4"><a href="2-lineaarne-regressioon.html#cb401-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb401-5"><a href="2-lineaarne-regressioon.html#cb401-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-6"><a href="2-lineaarne-regressioon.html#cb401-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Tõmbame  sisse andmestiku</span></span>
<span id="cb401-7"><a href="2-lineaarne-regressioon.html#cb401-7" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;https://github.com/mrksom/kvant/raw/master/data/piaac.csv&quot;</span>)</span>
<span id="cb401-8"><a href="2-lineaarne-regressioon.html#cb401-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb401-9"><a href="2-lineaarne-regressioon.html#cb401-9" aria-hidden="true" tabindex="-1"></a>piaac <span class="sc">%&gt;%</span> </span>
<span id="cb401-10"><a href="2-lineaarne-regressioon.html#cb401-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> numeracy, <span class="at">y =</span> sissetulek))<span class="sc">+</span></span>
<span id="cb401-11"><a href="2-lineaarne-regressioon.html#cb401-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>)<span class="sc">+</span></span>
<span id="cb401-12"><a href="2-lineaarne-regressioon.html#cb401-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/reg-plot-1-1.png" width="672" /></p>
<p>Tundub, et nende kahe tunnuse vahel on seos olemas. Mida kõrgem on matemaatilise kirjaoskuse skoor, seda kõrgem on sissetulek. Me saame selle suhte kokku võtta regressioonisirge abil. ggplotis on olemas vastav funktsioon <code>geom_smooth()</code>, mis selle joone meile graafikule paneb. Kuna me tahame saada lineaarse regressiooni sirget, siis peame <code>geom_smooth</code>’is kasutama argumenti <code>method = "lm"</code><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="2-lineaarne-regressioon.html#cb402-1" aria-hidden="true" tabindex="-1"></a>piaac <span class="sc">%&gt;%</span> </span>
<span id="cb402-2"><a href="2-lineaarne-regressioon.html#cb402-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> numeracy, <span class="at">y =</span> sissetulek))<span class="sc">+</span></span>
<span id="cb402-3"><a href="2-lineaarne-regressioon.html#cb402-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.5</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>)<span class="sc">+</span></span>
<span id="cb402-4"><a href="2-lineaarne-regressioon.html#cb402-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F, <span class="at">color =</span> <span class="st">&quot;#972D15&quot;</span>)<span class="sc">+</span></span>
<span id="cb402-5"><a href="2-lineaarne-regressioon.html#cb402-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/reg-plot-2-1.png" width="672" /></p>
<p>Regressioonisirge on väljendatav tavalise joone võrrandiga:</p>
<p><span class="math display">\[\begin{equation}
Y=a+bX
\end{equation}\]</span></p>
<p>kus <span class="math inline">\(a\)</span> on vabaliige (<em>intercept</em>) ja <span class="math inline">\(b\)</span> on sirge tõus (<em>slope</em>). Regressiooni kontekstis kutsutakse seda sirge tõusu regressioonikoefitsiendiks või regressioonikordajaks. Vabaliige tähistab <span class="math inline">\(Y\)</span> väärtust juhul kui <span class="math inline">\(X\)</span> on <span class="math inline">\(0\)</span> (sirge lõikumine y-teljega) ja sirge tõus ühikulist muutust <span class="math inline">\(Y\)</span> väärtuses kui <span class="math inline">\(X\)</span>-i väärtus muutub ühe ühiku võrra. Kui sirge tõus on positiivne, siis <span class="math inline">\(X\)</span>’i väärtuse kasvades <span class="math inline">\(Y\)</span> väärtus suureneb, kui negatiivne, siis kahaneb. Kui sirge tõus on aga <span class="math inline">\(0\)</span>, siis seos kahe tunnuse vahel puudub (iga <span class="math inline">\(X\)</span> väärtuse korral on keskmine <span class="math inline">\(Y\)</span> sama).</p>
<p>Linaarse regressioonanalüüsi eesmärgiks ongi leida parim võimalik sirge (st leida vabaliige ja regressioonikoefitsient, mis seda sirget määratlevad) tunnustevahelise lineaarse suhte kirjeldamiseks. Parim võimalik tähendab siinjuures seda, et see sirge läheb andmepunktide parvest läbi võimalikult keskelt, st kirjeldab kõiki punkte võimalikult hästi.</p>
</div>
<div id="regressioon-r-is" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Regressioon R-is<a href="2-lineaarne-regressioon.html#regressioon-r-is" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>R-is käib lihtsa regressioonimudeli tegemine <code>lm()</code> (<em>linear model</em>) funktsiooniga. Loomulikult on ka teisi funktsioone, mis regressiooni jooksutamisega hakkama saavad ja hea tahtmise korral võib vastava funktsiooni ka mõningase vaevaga ise valmis kirjutada. Kuid jätame teised variandid hetkel kõrvale.</p>
<p><code>lm()</code> funktsioonis tuleb defineerida regressioonivõrrand. Selleks peame määratlema sõltuva tunnuse, seejärel kasutama tildet (<code>~</code>) ning seejärel määratlema sõltumatu(d) tunnuse(d): <code>sõltuv_tunnus ~ sõltumatu_tunnus</code><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<p>Saaksime ka vabaliikme võrrandisse sisse kirjutada: <code>sõltuv_tunnus ~ 1 + sõltumatu_tunnus</code>. Vabaliige on alati tähistatud <code>1</code>-ga ja kuna ta on alati mudelis olemas, siis R lisab selle ise vaikimisi võrrandisse ning seega me tegelikult ei pea seda eksplitsiitselt välja kirjutama. Küll aga saame selle abil moodustada ainult vabaliikmega mudeli. See oleks nn nullmudel ehk tegelikult lihtsalt sõltuva tunnuse keskmise mudel. Defineerime sellise mudeli:</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="2-lineaarne-regressioon.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sissetulek <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> piaac)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ 1, data = piaac)
## 
## Coefficients:
## (Intercept)  
##       855.5</code></pre>
<p>Tulemiks on mudeli vabaliikme <em>(Intercept)</em> väärtus, mis juhul kui ühtegi sõltumatut tunnust mudelis ei ole, on lihtsalt keskmine sissetulek. Täpselt sama tulemuse saame <code>mean()</code> funktsiooniga:</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="2-lineaarne-regressioon.html#cb405-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(piaac<span class="sc">$</span>sissetulek, <span class="at">na.rm =</span> T)</span></code></pre></div>
<pre><code>## [1] 855.4557</code></pre>
<p>Kui me tahame inimeste heaolu või hakkamasaamist uurida, siis annab keskmise sissetulek meile selle jaoks kindlasti mingit lähtekoha, kuid lihtne keskmine ei ole just aga ülemäära informatiivne. Me ju teame, et erinevatel inimestel on erinevad sissetulekud, ning tegelikult huvitaks meid asjaolud mis seda sissetulekute erinevust põhjustavad.</p>
<p>Siin tulebki mängu regressioonanalüüs, mis võimaldab uurida kuidas eri tunnused mõjutavad sissetulekute erinevust. Näiteks saaksime vaadata, kas matemaatilise kirjaoskuse tase mõjutab mingitpidi keskmist sissetulekut, ehk siis kas erineva matemaatilise kirjaoskusega inimeste keskmised sissetulekud erinevad. Ja kui erinevad, siis kui palju nad erinevad.</p>
<p>Defineerimegi järgmisena regressioonimudeli, kuhu lisame sõltumatu tunnusena matemaatilise kirjaoskuse ja millega hindame matemaatilise kirjaoskuse mõju sissetulekule<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>:</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="2-lineaarne-regressioon.html#cb407-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sissetulek <span class="sc">~</span> numeracy, <span class="at">data =</span> piaac)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ numeracy, data = piaac)
## 
## Coefficients:
## (Intercept)     numeracy  
##    -140.887        3.606</code></pre>
<p>Lihtsalt <code>lm()</code> funktsiooni jookustades saame nüüd kaks numbrit - vabaliikme (<em>intercept</em>), mis antud näite puhul on <span class="math inline">\(-140\)</span>, ja regressioonikoefitsiendi (<em>regression coefficient</em>), mis antud näite puhul on <span class="math inline">\(3.6\)</span>. Mida need meile ütlevad? Nagu eelnevalt juttu oli, siis vabaliige on <span class="math inline">\(Y\)</span> väärtus kui <span class="math inline">\(X\)</span> on <span class="math inline">\(0\)</span>, ehk siis inimesel, kelle matemaatilise kirjaoskuse skoor on <span class="math inline">\(0\)</span>, peaks meie mudeli kohaselt sissetulek olema <span class="math inline">\(-140\)</span>. Regressioonikoefitsient aga annab meile teada kui palju <span class="math inline">\(Y\)</span> muutub, kui <span class="math inline">\(X\)</span> muutub ühe ühiku võrra, ehk siis kui matemaatilise kirjaoskuse skoor tõuseb ühe punkti võrra, tõuseb sissetulek keskmiselt <span class="math inline">\(3.6\)</span> euro võrra.</p>
<p>Näeme, et vabaliikme väärtus on negatiivne, mis ei ole ju tegelikult reaalselt võimalik olukord - sissetulek ei saa olla negatiivne. Taoline olukord tekkis seetõttu, et Piaaci testis ei saa ka matemaatilise kirjaoskuse skoor <span class="math inline">\(0\)</span> olla ning seega ebareaalsele sõltumatu tunnuse väärtusele vastab mudelis ebareaalne sõltuva tunnuse väärtus. Selliseid olukordi, kus sõltumatu tunnuse <span class="math inline">\(0\)</span> väärtus on ebareaalne (näiteks pikkus, kaal jne), tuleb päris sageli ette, mis tähendab, et üldjuhul ei ole vabaliikme väärtus omaette sisuliselt oluline (küll aga on see oluline terve mudeli kontekstis). Tegelikult saame sõltumatuid tunnuseid transformeerides (näiteks kui standardiseerime matemaatilise kirjaoskuse taseme nii, et keskmine tase oleks 0) selle väärtuse ka sisukaks teha, kuid sellest natuke hiljem.</p>
<p>Nüüd, kui teame mudeli parameetreid, saame nende abil regressioonijoone graafikule kanda ka ilma <code>geom_smooth</code>’ita:</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="2-lineaarne-regressioon.html#cb409-1" aria-hidden="true" tabindex="-1"></a>piaac <span class="sc">%&gt;%</span> </span>
<span id="cb409-2"><a href="2-lineaarne-regressioon.html#cb409-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> numeracy, <span class="at">y =</span> sissetulek))<span class="sc">+</span></span>
<span id="cb409-3"><a href="2-lineaarne-regressioon.html#cb409-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>)<span class="sc">+</span></span>
<span id="cb409-4"><a href="2-lineaarne-regressioon.html#cb409-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="fl">3.6</span>, <span class="at">intercept =</span> <span class="sc">-</span><span class="dv">140</span>, <span class="at">color =</span> <span class="st">&quot;#972D15&quot;</span>)<span class="sc">+</span></span>
<span id="cb409-5"><a href="2-lineaarne-regressioon.html#cb409-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">450</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">3500</span>))<span class="sc">+</span></span>
<span id="cb409-6"><a href="2-lineaarne-regressioon.html#cb409-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/reg-plot-3-1.png" width="672" /></p>
<p>Kui me peaksime prognoosima mõnele inimesele tema sissetulekud, siis nullmudeli puhul oleks meie parim pakkumine kogu populatsiooni keskmine sissetulek. Regressioonimudeliga saame teha juba täpsema prognoosid ja arvesse võtta ka sõltumatust tunnusest tulevat variatiivsust keskmises sissetulekus. Kui me teame regressioonisirge tõusu ehk regressioonikoefitsienti ja vabaliiget, siis lähtuvalt sõltumatu tunnuse väärtustest saame prognoosida sõltuva tunnuse väärtuse:</p>
<p><span class="math display">\[\begin{equation}
  \hat{y}_i=b_0+b_1x_i
\end{equation}\]</span></p>
<p><span class="math inline">\(\hat{y}_i\)</span> antud võrrandis tähistab hinnatud või prognoositud <span class="math inline">\(y\)</span> väärtust (sellest ka see müts <span class="math inline">\(y\)</span> peal) vaatlusele <span class="math inline">\(i\)</span>. Kui meil on regressioonivõrrand <span class="math inline">\(\hat{y}_i=-140+3.6x_i\)</span> ja meil on mingi vaatlus <span class="math inline">\(i\)</span>, mille <span class="math inline">\(x\)</span> väärtus on näiteks 200, siis saame sellele vaatlusele prognoosida <span class="math inline">\(y\)</span> väärtuseks:</p>
<p><span class="math display">\[\begin{equation}
  -140+3.6\times200=580
\end{equation}\]</span></p>
<p>Ehk siis inimesel, kelle matemaatilise kirjaoskuse skoor on 200, peaks meie mudeli järgi sissetulek olema keskmiselt <em>ca</em> 580 eurot. Inimesel, kelle matemaatilise kirjaoskuse skoor on 400, peaks sissetulek olema keskmiselt <span class="math inline">\(-140+3.6\times400=1300\)</span> eurot</p>
<div class="figure"><span style="display:block;" id="fig:reg-plot-4"></span>
<p class="caption">
Joonis 2.1: Prognoosime y väärtust kui x on 200 ja kui x = 400
</p>
<img src="01-regressioon_files/figure-html/reg-plot-4-1.png" alt="Prognoosime y väärtust kui x on 200 ja kui x = 400" width="672" />
</div>
</div>
<div id="regressiooni-jäägid" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Regressiooni jäägid<a href="2-lineaarne-regressioon.html#regressiooni-jäägid" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Kui me prognoosime oma regressioonisirge alusel kellelegi sissetulekut, siis peame arvestama, et prognoositav keskmine sisaldab alati ka teatavat viga (samamoodi, nagu tavaline keskmine sisaldab viga, mis on väljendatav standardhälbena). Võimatu on ühe sirgega kõiki punkte ideaalselt kirjeldada. Iga punkti ja sirge vahele jääb alati mingi viga, või teisisõnu, kõik punktid (või vähemalt enamus neist) hälbivad suuremal või vähemal määral regressioonisirgest.</p>
<p>Mida suuremad need hälbed on, seda vähem suudab on meie mudel (regressioonisirge) kirjeldada sõltuva tunnuse variatsiooni ja seda suurem on vea määr meie mudelis. Neid hälbeid kutusutakse <strong>regressiooni jääkideks</strong> (<em>regression residuals</em>).</p>
<div class="figure"><span style="display:block;" id="fig:reg-plot-5"></span>
<p class="caption">
Joonis 2.2: Regressiooni jäägid
</p>
<img src="01-regressioon_files/figure-html/reg-plot-5-1.png" alt="Regressiooni jäägid" width="672" />
</div>
<p>Ehk siis iga kord, kui prognoosime <span class="math inline">\(\hat{y}_i=\beta_0+\beta_1x_i\)</span> abil <span class="math inline">\(y_i\)</span> väärtust, teeme me mingi vea<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>. Seetõttu tuleb regressioonivõrrandile lisada vea komponent (<span class="math inline">\(\epsilon\)</span>) ning võrrand ise muutub vastavalt:</p>
<p><span class="math display">\[\begin{equation}
  \hat{y_i}=\beta_0+\beta x_i+\epsilon_i
\end{equation}\]</span></p>
<p>Kõige parem regressioonisirge annab joon, mille puhul jäägid on minimaalsed, ehk siis joon, mille puhul kõikide vaatluste jääkide summa oleks võimalikult väike. Kuna me ei saa jääke kokku võtta neid lihtsalt kokku liites (<em>ca</em> pooled jäägid on väiksemad kui regressioonijoon ja <em>ca</em> pooled suuremad, seega nende summa oleks <span class="math inline">\(0\)</span>), siis tuleb nad enne liitmist ruutu panna. Ja meie eesmärgiks on nüüd leida regressioonisirge, mis minimeeriks <strong>ruutjääkide summa</strong> (<em>residual sum of squares</em> ehk <span class="math inline">\(RSS\)</span>) ehk siis regressioonisirge, mille puhul <span class="math inline">\(RSS\)</span> oleks võimalikult väike<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>.</p>
<p>Eelnevast lähtuvalt on ka küllaltki loogiline, et meetodit, millega <span class="math inline">\(RSS\)</span> minimeeritakse ja regressioonisirge ning vastavad koefitsiendid leitakse, nimetatakse <strong>vähimruutude meetodiks</strong>.</p>
<div class="teie-kord">
<p>Ülesanne!</p>
<ul>
<li>Kasutades ggplot’i ja tehke punktdiagramm <code>geom_point()</code> matemaatilise kirjaoskuse (<em>numeracy</em>) ja funktsionaalse lugemisoskuse (<em>literacy</em>) vahelisest seosest. Pange <em>numeracy</em> x-teljele ja <em>literacy</em> y-teljele.<br />
</li>
<li>Kasutades <code>geom_abline()</code>’i, lisage joonisele lineaarne regressioonijoon (seega peate eelnevalt <code>lm()</code> funktsiooniga leidma regressioonijoone vabaliikme ja regressioonikoefitsiendi)</li>
</ul>
</div>
</div>
<div id="regressioonimudeli-sobitumine" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Regressioonimudeli sobitumine<a href="2-lineaarne-regressioon.html#regressioonimudeli-sobitumine" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Olles leidnud joone, mis kirjeldab kahe tunnuse vahelist seost kõige paremini, võiks ju eeldada, et ülesanne on täidetud. Aga kas ikka on? Ükskõik, millisest punktiparvest võib regressioonijoone läbi panna. Kuid tulenevalt regressioonijääkide (vaatluste hälbed regressioonijoonest) suurusest saame selle joone kohta teha väga erinevaid järeldusi. Kui jäägid on väikesed, siis võime suhteliselt täpselt prognoosida sõltuva tunnuse väärtust või teha järeldusi seose kohta. Kuid mida suuremad on jäägid, seda ebatäpsem on ka meie prognoos/järeldus.</p>
<p>Üldjuhul kasutame regresioonanalüüsi, et teha valimi baasil järeldusi mingi üldkogumi kohta. Meid huvitab, kas see seos, mida näeme oma valimi andmete põhjal, kehtib ka üldkogumis. Saame küll eeldada, et valimipõhiselt leitud regressioonisirge on suhteliselt sarnane üldkogumi sirgele (sirge, mille me saaksime, kui kaasaksime analüüsi kõik üldkogumi liikmed), aga kui sarnane, seda me ei tea. Kui me võtaksime samast üldkogumist teise valimi, siis juhul kui mõlemad valimid on võetud korrektselt<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> ja valimid on piisavalt suured, siis peaksid nende põhjal leitud regressioonisirged olema suhteliselt sarnased, aga identsed ei ole nad praktiliselt kunagi. Kõikide võimalike valimite puhul me mingil määral alahindame või ülehindame tegelikku, populatsiooni regressioonikoefitsienti (ja ka vabaliiget). Seega, et saada aimu valimipõhise hinnangu täpsusest (vastavusest tegelikule tegelikule üldkogumi parameetrile), peaksime kuidagi välja selgitama valimi kasutamisest tuleneva vea võimaliku suuruse.</p>
<p>Et hinnata mudeli sobivust andmetega ja sellega leitud hinnagute täpsust, vajame mudeli kohta täiendavat infot. Eelnevalt regressioonimudelit <code>lm()</code> funktsiooniga jooksutades oli väljund väga lakooniline. Saime teada ainult vabaliikme ja regressioonikoefitsinedi väärtused. Tegelikult on <code>lm()</code> tulem muidugi märksa põhjalikum. Muule mudeliga kaasnevale infole saame ligi kui salvestame mudeli esmalt mingisse andmeobjekti ja kasutame selle andmeobjekti peal <code>summary()</code> käsku<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="2-lineaarne-regressioon.html#cb410-1" aria-hidden="true" tabindex="-1"></a>mudel1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> numeracy, <span class="at">data =</span> piaac)</span>
<span id="cb410-2"><a href="2-lineaarne-regressioon.html#cb410-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ numeracy, data = piaac)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1016.7  -351.5  -129.1   179.4  2923.4 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -140.887     56.510  -2.493   0.0127 *  
## numeracy       3.606      0.202  17.849   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 555.8 on 3982 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.07408,    Adjusted R-squared:  0.07385 
## F-statistic: 318.6 on 1 and 3982 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="2-lineaarne-regressioon.html#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Kui me ei taha mudelit salvestada, siis saab ka nii:</span></span>
<span id="cb412-2"><a href="2-lineaarne-regressioon.html#cb412-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(numeracy <span class="sc">~</span> literacy, <span class="at">data =</span> piaac))</span></code></pre></div>
<p>Nüüd näeme juba märksa põhjalikumat väljundit. Vaatame mis seal kirjas on ja kuidas seda tõlgendada. Käime väljundi sektsioonide kaupa läbi (v.a. esimene rida, mis on vist niigi suht selge)</p>
<div id="jääkide-jaotus" class="section level3 hasAnchor" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> Jääkide jaotus<a href="2-lineaarne-regressioon.html#jääkide-jaotus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<pre><code>## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1016.7  -351.5  -129.1   179.4  2923.4</code></pre>
<p>Väljundis on kirjeldatud regressiooni jääkide (<em>residuals</em>) jaotus. Enne nägime, et regressiooni jäägid on regressioonijoone ja tegelike, vaadeldud väärtuste vahe. Mida väiksemad on jäägid, seda täpsemini kirjeldab regressioonijoon andmete vahelist seost. Nägime ka, et pooled jäägid peaksid ideaalis olema suuremad (positiivse märgiga) kui regressioonisirge ja pooled väiksemad (negatiivse märgiga). Seega peaks jääkide keskmine olema ligikaudu <span class="math inline">\(0\)</span> ning jääkide jaotus normaaljaotuse sarnane, kus esimene ja kolmas kvartiil, aga ka maksimum ja miinimum, on keskväärtusest umbes sama kaugel. Hiljem vaatame jääkide jaotust ka graafiliselt, mis on märksa mõistlikum viis neid uurida, kuid esmase mulje saab ka siit kätte.</p>
</div>
<div id="regressioonikoefitsiendid-ja-nende-olulisus" class="section level3 hasAnchor" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Regressioonikoefitsiendid ja nende olulisus<a href="2-lineaarne-regressioon.html#regressioonikoefitsiendid-ja-nende-olulisus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<pre><code>##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -140.887     56.510  -2.493   0.0127 *  
## numeracy       3.606      0.202  17.849   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Koefitsientide sektsioonis on esitatud mudeli oluliseim info. <strong><em>Estimate</em></strong> on hinnang mudeliga leitud regressioonikoefitsientidele. Lihtsa regressiooni puhul on meil ainult vabaliige ja ühe sõltumatu tunnuse koefitsient. Hiljem, mitmese regressiooni kontekstis, on neid koefitsiente rohkem. Vabaliikmeid on aga mudeli kohta alati üks.</p>
<p>Tulbas <strong><em>Std. Error</em></strong> on toodud koefitsientide standardvead. Standardviga kirjeldab meie mudeli hinnangus sisalduvat määramatust. Me kasutame regressioonikoefitsientide leidmiseks üldjuhul valimipõhiseid andmeid, kuigi tegelikult huvitavad meid ju üldkogums esinevad seosed. Valimipõhine hinnang peaks piisavalt suure valimi korral olema tõenäoliselt küllaltki sarnane üldkogumi vastavale parameetrile, kuid väikese valimi korral puhta juhuse läbi sellest arvestatavalt erineda. Standardviga näitabki kui kindlad me oma mudeli hinnangus olla saame. Mida väiksem on standardviga (võrreldes hinnangu endaga), seda kindlamad võime olla ka oma hinnangus. Standardvea suurs sõltub eelkõige jääkide hajuvusest ja valimi suurusest. Mida väiksemad on jäägid ja mida suurem on valim, seda väiksem on ka standardviga.</p>
<p>Standardvea abil saame <em>t</em>-testi abil testida, kas regressioonikoefitsient erineb oluliselt nullist (kui koefitsient on null, siis seos tunnuste vahel puudub). <em>t</em>-testi tulemust näitab veerg <strong><em>t value</em></strong>. <em>t</em>-väärtus ütleb meile kui mitme standardvea kaugusel meie regressioonikoefitsient 0-st on. Kui on piisavalt kaugel, siis saame järeldada, et leitud koefitsient on ka üldkogumis 0-st erinev. Kui kaugel on aga piisavalt kaugel? See sõltub sellest, kui suurt vea tõenäosust me oleme valmis tolereerima (mingi vea tõenäosus jääb seejuures alati). Üldjuhul valitakse selleks tõenäosuseks <span class="math inline">\(5\%\)</span> (ütleme, et regressioonikoefitsient on statistiliselt oluline usaldusnivool <span class="math inline">\(95 \%\)</span> või olulisusnivool <span class="math inline">\(p &lt; 0.05\)</span>), aga see võib olla ka <span class="math inline">\(1\%\)</span> või <span class="math inline">\(10\%\)</span>. Siin tegelikult ei ole mingit väga konkreetset piirmäära, millest juhinduda. Kui me aga lepime kokku, et võimaliku vea tõenäosusena aktsepteerime <span class="math inline">\(5\)</span>-te protsenti, siis peab <em>t</em>-väärtus olema suurem kui <em>ca</em> <span class="math inline">\(\pm2\)</span> (täpne väärtus sõltub vaatluste arvust). Antud näite puhul on <em>t</em>-väärtused <span class="math inline">\(-2.5\)</span> ja <span class="math inline">\(17.8\)</span>, ehk siis mõnevõrra suuremad kui <span class="math inline">\(\pm2\)</span> ja me võime järeldada, et nii vabaliige kui regressioonikoefitsient erinevad olulisusnivool <span class="math inline">\(95\%\)</span> oluliselt nullist (kuigi jah, vabaliige on suhteliselt piiri peal).</p>
<p>Õnneks ei pea me seda täpset <em>t</em>-väärtuse piirmäära ise välja nuputama. R arvutab meile automaatselt võimaliku vea tõenäosuse konkreetse <em>t</em>-väärtuse kohta. See tõenäosus on ära toodud veerus <strong><em>Pr(&gt;|t|)</em></strong> ja seda nimetatakse <em>p</em>-väärtuseks. <em>p</em>-väärtuse tõlgendus on: kui tõenäoline on, et me saaksime niivõrd suure või suurema <em>t</em>-väärtuse nagu me saime, kui regressioonikoefitsient oleks üldkogumis tegelikult <span class="math inline">\(0\)</span>. Seega kui <em>p</em>-väärtus on näiteks <span class="math inline">\(0.04\)</span>, siis oleks tõenäosus, et me saaksime sellise regressioonikoefitsiendi, juhul kui üldkogumis oleks regressioonikoefitsient tegelikult <span class="math inline">\(0\)</span> (ehk tunnuste vahe seost ei oleks), <span class="math inline">\(0.04\)</span> ehk <span class="math inline">\(4\)</span>% või väiksem. Üldjuhul tahaksime näha <em>p</em>-väärtust, mis on väiksem kui <span class="math inline">\(0.05\)</span>. Sellisel juhul oleks koefitsient statistiliselt oluline usaldusnivool <span class="math inline">\(95\%\)</span>. Antud näites on meil regressioonikoefitsiendi puhul tegemist väga väikeste <em>p</em> väärtustega (&lt;2e-16 tähendab väiksem kui <span class="math inline">\(2\times10^{-16}\)</span>) ja me võime olla päris kindlad, et koefitsient erineb nullist. Vabaliikme <em>p</em>-väärtus on aga <span class="math inline">\(0.012\)</span>, ehk kui me kasutaksime usaldusnivood <span class="math inline">\(99\%\)</span> (mille puhul <em>p</em>-väärtus peaks olema väiksem kui <span class="math inline">\(0.01\)</span>), siis me ei saaks järeldada, et see on statistiliselt oluliselt erinev nullist. Lisaks kuvab R iga <em>p</em>-väärtuse taha ka tärnid, mis indikeerivad selle väärtuse suurust lähtuvalt allolevast legendist.</p>
<p>Miks meil on üldse vaja teada kas koefitsiendid erinevad oluliselt nullist? Aga sellepärast, et kui regressioonisirge oleks <span class="math inline">\(0\)</span>, siis meie tunnuste vahel ei oleks seost (kui <span class="math inline">\(X\)</span> muutub <span class="math inline">\(1\)</span> ühiku võrra, siis <span class="math inline">\(Y\)</span> muutub <span class="math inline">\(0\)</span> ühiku võrra, ehk siis <span class="math inline">\(Y\)</span> väärtus ei sõltu <span class="math inline">\(X\)</span>’i väärtusest). Aga kuidas on lood vabaliikmega? Kas ka see peab erinema nullist, et meie mudelist mingit tolku oleks? Tegelikult ju ei pea. Võib täitsa vabalt juhtuda, et regressioonisirge lähebki läbi <span class="math inline">\(X\)</span> ja <span class="math inline">\(Y\)</span> telgede ristumiskoha (<span class="math inline">\(Y\)</span> on <span class="math inline">\(0\)</span> kui <span class="math inline">\(X\)</span> on <span class="math inline">\(0\)</span>). Sellisel juhul oleks vabaliikme <em>t</em>-väärtus väiksem kui <span class="math inline">\(2\)</span> ja <em>p</em>-väärtus suurem kui 0.05, kuid mudeli tõlgendust see ei mõjutaks. Ehk siis tavaliselt meid vabaliikme <em>p</em> ja <em>t</em> väärtused väga ei huvita. Küll aga peaks jälgima, et standardviga väga suur (võrreldes vabaliikme endaga) ei oleks.</p>
</div>
<div id="jääkide-standardviga" class="section level3 hasAnchor" number="2.4.3">
<h3><span class="header-section-number">2.4.3</span> Jääkide standardviga<a href="2-lineaarne-regressioon.html#jääkide-standardviga" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<pre><code>## Residual standard error: 555.8 on 3982 degrees of freedom
##   (3648 observations deleted due to missingness)</code></pre>
<p>Kuidas hinnata regressiooniprognoosi täpsust, ehk siis seda kui hästi regressioonimudel sobitub andmetega (<em>model fit</em>)? Üheks võimaluseks on lähtuda samast loogikast mida kasutame tunnuse keskväärtuse täpsuse hindamisel. Ehk kui palju vaatlused keskmiselt erinevad keskväärtusest. Regressioonijoone puhul ei ole meil ühte keskväärtust, mille suhtes vaatluste hälbimist määrata. Kuid iga vaatluse sõltumatu tunnuse väärtuse <span class="math inline">\(x\)</span> kohta on meil “hinnatud” sõltuva tunnuse väärtus <span class="math inline">\(\hat{y}\)</span>. Seega tuleb meil lihtsalt vaadata kui palju vaatluste <span class="math inline">\(y\)</span> ja <span class="math inline">\(\hat{y}\)</span> väärtused keskmiselt erinevad, ehk kui suur on keskmine viga meie mudelis. Regressioonanalüüsi kontekstis kutsutakse seda vaatluste varieeruvuse näitajat keskmiseks ruutveaks (<em>mean squared error</em>) ehk lühidalt <span class="math inline">\(MSE\)</span>:</p>
<p><span class="math display">\[\begin{equation}
  MSE=\frac{\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{n-k}
\end{equation}\]</span></p>
<p>kus <span class="math inline">\(n\)</span> on vaatluste arv ja <span class="math inline">\(k\)</span> on regressioonikoefitsientide arv (kaasa arvatud vabaliige).</p>
<p>Kuna aga <span class="math inline">\(MSE\)</span> väärtus on ruudus, siis on seda keeruline interpreteerida (samamoodi nagu ka dispersiooni). Kui me võtame ruutjuure <span class="math inline">\(MSE\)</span>’st, <span class="math inline">\(\sqrt{MSE}\)</span>, saame regressiooni jääkide standardhälbe, mida nimetatakse <strong>jääkide standardveaks</strong> (<em>residual standard error</em> ehk RSE). RSE näitab kui palju vaatlused keskmiselt hälbivad regressioonijoonest (analoogne keskmise standardhälbega). Mida väiksem on mudeli RSE, seda paremini mudel andmetega sobitub (seda vähem hälbivad vaatlused regressioonijoonest ehk seda väiksemad on regresiooni jäägid). See, kui väike peaks RSE väärtus hea mudeli korral olema, sõltub sõltuva tunnuse skaalast (samamoodi nagu keskväärtuse standardhälve). Mingeid konkreetseid piirväärtusi siinkohal tuua ei ole võimalik.<br />
Lisaks on siin ära toodud ka <em>degrees of freedom</em> ehk vabadusastmete arv jääkide standardvea arvutamisel. Sisuliselt on siin kirjas analüüsi kaasatud vaatluste arv (miinus regressioonikordajate arv, siinses mudelis 2). Ära on toodud ka analüüsist välja jäetud vaatluste arv. Need on need, kellel puudus väärtus vähemalt ühe analüüsitava tunnuse jaoks.</p>
</div>
<div id="r-ruut" class="section level3 hasAnchor" number="2.4.4">
<h3><span class="header-section-number">2.4.4</span> R ruut<a href="2-lineaarne-regressioon.html#r-ruut" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<pre><code>## Multiple R-squared:  0.07408,    Adjusted R-squared:  0.07385</code></pre>
<p>Vast oluliseimaks mudeli headuse näitajaks on <span class="math inline">\(R^2\)</span>. Regressioonanalüüsi eesmärk on seletada mingit osa sõltuva tunnuse variatiivsusest sõltumatu tunnuse abil. Seega saame regressioonimudeli puhul hinnata ja mudeli kvaliteedi iseloomustusena kasutada sõltumatu tunnuse poolt seletatud variatiivsuse osakaalu sõltuva tunnuse koguvariatiivsusest. Sõltuva tunnuse variatiivsuse (seda nimetatakse <span class="math inline">\(TSS\)</span> ehk <em>total sums of squares</em>) saab jagada komponentideks: variatiivsus, mis on seletatud regressioonijoone poolt (<span class="math inline">\(ESS\)</span> ehk <em>explained sums of squares</em>) ja variatiivsus, mis ei ole regressioonijoone poolt seletatud ehk siis mudeli seisukohast viga (<span class="math inline">\(RSS\)</span> ehk <em>residual sums of squares</em>):</p>
<p><span class="math display">\[TSS=RSS+ESS\]</span></p>
<p><span class="math display">\[\begin{equation}
  ESS=\sum_{i=1}^{n}(\hat{y}_i-\bar{y})^2
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  RSS=\sum_{i=1}^{n}(y_i-\hat{y}_i)^2
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  TSS=\sum_{i=1}^{n}(y_i-\bar{y})^2
\end{equation}\]</span></p>
<div class="figure"><span style="display:block;" id="fig:ss"></span>
<p class="caption">
Joonis 2.3: Variatsiivsuse jagunemine
</p>
<img src="01-regressioon_files/figure-html/ss-1.png" alt="Variatsiivsuse jagunemine" width="672" />
</div>
<p>Teades erinevaid variatiivsuse komponente, saame määrata kui suur osa (mitu protsenti) sõltuva tunnuse koguvariatsioonist on seletatav regressioonijoone poolt (ehk siis sõltumatu tunnuse poolt). Seda suurust nimetatakse <strong>determinatsioonikordajaks</strong> ehk lühidalt <span class="math inline">\(R^2\)</span>-ks.</p>
<p><span class="math display">\[\begin{equation}
  R^2=\frac{TSS-RSS}{TSS}=1-\frac{RSS}{TSS}
\end{equation}\]</span></p>
<p><span class="math inline">\(R^2\)</span> jääb vahemikku <span class="math inline">\(0-1\)</span>. See mõõdab seose tugevust, st mida lähemal <span class="math inline">\(R^2\)</span> on <span class="math inline">\(1\)</span>’le, seda tugevam lineaarne seos tunnuste vahel on ja seda enam sõltumatu tunnus sõltuva tunnuse variatsiooni seletab, seega seda efektiivsem on regressioonifunktsiooni kasutamine selle asemel, et lihtsalt sõltuva tunnuse keskmist hinnata (kui <span class="math inline">\(R^2\)</span> on <span class="math inline">\(0\)</span>, siis regressioonijoon langeb kokku sõltuva tunnuse keskmist tähistava joonega, st et <span class="math inline">\(ESS=0\)</span> ja <span class="math inline">\(TSS=RSS\)</span>).</p>
<p>R annab meile lisaks tavalisele <span class="math inline">\(R^2\)</span> väärtusele (<em>Multiple R-squared</em>) ka nn korrigeeritud <span class="math inline">\(R^2\)</span> väärtuse (<em>Adjusted R-squared</em>). Korrigeeritud <span class="math inline">\(R^2\)</span> puhul võetakse arvesse ka sõltumatute tunnuste arvu. Iga lisanduva sõltumatu tunnusega läheb “tavaline” <span class="math inline">\(R^2\)</span> suuremaks. Kui lisanduv tunnus eriti midagi ei seleta, siis võib see tõus olla väga väike, kuid mingi tõus paratamatult on. Korrigeeritud <span class="math inline">\(R^2\)</span>, arvestades oma valemis ka sõltumatute tunnuste arvu, annab mitme sõltumatu tunnuse korral korrektsema tulemuse. Hetkel, lihtsa regressiooni kontekstis, kus meil on ainult üks sõltumatu tunnus, annavad mõlemad variandid (enam-vähem) sama tulemuse.</p>
</div>
<div id="f-väärtus-ja-f-test" class="section level3 hasAnchor" number="2.4.5">
<h3><span class="header-section-number">2.4.5</span> F-väärtus ja F-test<a href="2-lineaarne-regressioon.html#f-väärtus-ja-f-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<pre><code>## F-statistic: 318.6 on 1 and 3982 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>F</em>-väärtus, sarnaselt <em>t</em>-väärtusele, aitab meil hinnata kas meie mudel on statistiliselt oluline, ehk siis kas meie analüüsitavate tunnuste vahel on oluline lineaarne seos. <em>F</em>-väärtuseks nimetatakse mudeli abil seletatud variatiivsuse ja seletamata variatiivsuse suhet:</p>
<p><span class="math display">\[\begin{equation}
\text{F-suhe} = \frac{\text{regressioonimudeli poolt seletatud variatiivsus}}{\text{regressioonimudeli poolt seletamata variatiivus}}
\end{equation}\]</span></p>
<p>Natuke täpsemalt väljendades:</p>
<p><span class="math display">\[F = \frac{(TSS-RSS)/(k-1)}{RSS/(n-k)}\]</span></p>
<p>kus <span class="math inline">\(n\)</span> on valimi suurus ja <span class="math inline">\(k\)</span> on regressioonikoefitsientide (sõltumatute muutujate) arv.</p>
<p>Kui mudeli regressioonisirge on <span class="math inline">\(0\)</span>, siis peaks see suhe olema <span class="math inline">\(1\)</span>. See tähendab, et regressioonisirge ei seleta üldse sõltuva tunnuse varieeruvust. Kui regressioonisirge on suurem kui <span class="math inline">\(0\)</span> siis peaks regressioonisirge poolt seletatud varieeruvus (koos juhusliku varieeruvusega) olema suurem kui ainult juhuslik dispersioon. Saame jällegi kasutada <em>F</em>-väärtusega kaasnevat <em>p</em> väärtust, et hinnata kas see <em>F</em>-väärtus on piisavalt suur, et saaksime mudelist lähtuvalt mingeid sisukaid järeldusi teha.</p>
<p>Võite märgata, et t-test ja F-test annavad meie mudeli puhul sama <em>p</em> väärtuse. Ja tegelikult annavad nad ka sama teststatistiku. <em>t</em>-statistik on lihtsalt ruutjuur <em>F</em>-statistikust<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. Võib tekkida küsimus, et miks me siis kahte testi peame kasutama. Ühe sõltumatu tunnusega regressioonimudelis otseselt ei peagi. Samas kui meil on mitu sõltumatut tunnust (nagu meil hiljem on), siis <em>F</em> ja <em>t</em> väärtused muutuvad. <em>F</em>-testiga saab sel juhul testida terve mudeli headust, st kas meie sõltumatud tunnused koos suudavad seletada piisavalt sõltuva tunnuse variatiivsust (tegelikult testib <em>F</em>-test seda, et kas vähemalt üks koefitsientidest erineb nullist). <em>t</em>-statistikud aga arvutatakse igale regressioonikoefitsiendile eraldi ning nendega saame kontrollida iga üksiku koefitsiendi erinevust nullist.</p>
<div class="teie-kord">
<p>Ülesanne!</p>
<ul>
<li>Looge regressioonimudel, millega hindate <em>numeracy</em> mõju <em>literacy</em>’le.<br />
</li>
<li>Salvestage see mudel ja uurige <code>summary()</code> funktsiooniga.</li>
<li>Kas <em>numeracy</em> mõju <em>literacy</em>’le on statistiliselt oluline?<br />
</li>
<li>Mitu protsenti <em>literacy</em> variatsioonist on selgitatav läbi <em>numeracy</em>?</li>
</ul>
</div>
</div>
</div>
<div id="kategoriaalsed-tunnused-regressioonis" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Kategoriaalsed tunnused regressioonis<a href="2-lineaarne-regressioon.html#kategoriaalsed-tunnused-regressioonis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="üks-binaarne-sõltumatu-tunnus" class="section level3 hasAnchor" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> Üks binaarne sõltumatu tunnus<a href="2-lineaarne-regressioon.html#üks-binaarne-sõltumatu-tunnus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Siiani oleme käsitlenud ainult mudeleid, kus sõltumatuteks tunnusteks on pidevad muutujad. Kuid me saame mudelisse lülitada ka kategoriaalseid tunnuseid. Vaatame esmalt mudelit, kus on üks kategoriaalne sõltumatu muutuja<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>. Teeme Piaaci andmete põhjal mudeli, millega hindame soo mõju sissetulekule.</p>
<p>Kõigepealt peame kategoriaalse tunnuse dihhotomiseerima. Binaarse tunnuse puhul, nagu sugu, on see lihtne. Kodeerime selle lihtsalt ümber väärtusteks <span class="math inline">\(0\)</span> ja <span class="math inline">\(1\)</span> (vastavalt mees ja naine)?</p>
<p><span class="math display">\[ x_{i} =
  \begin{cases}
    1  &amp; \quad \text{kui on naine}\\
    0  &amp; \quad \text{kui on mees}
  \end{cases}
\]</span></p>
<p>Tegelikult R oskab selle dihhotomiseerimise ise ära teha ja me saame võrrandisse sisestada tunnuse tema algsel kujul. Kuid oluline on teada, et mudeli siseselt on tegemist <span class="math inline">\(1/0\)</span> tunnusega.</p>
<p>Seega, meil on tunnus <span class="math inline">\(x\)</span> (sugu) kahe kategooriaga, kus <span class="math inline">\(0\)</span> - mees ja <span class="math inline">\(1\)</span> - naine. Kui me selle tunnuse nüüd regressioonivõrrandisse paneme, siis mis on <span class="math inline">\(y_i\)</span> väärtus kui <span class="math inline">\(x_i\)</span> on <span class="math inline">\(1\)</span> (ehk siis vaatluse sugu on naine) ja mis on <span class="math inline">\(y_i\)</span> väärtus kui <span class="math inline">\(x_i\)</span> on <span class="math inline">\(0\)</span> (ehk siis vaatluse sugu on mees)?</p>
<p><span class="math display">\[ \hat{y_i}=\beta_0+\beta_1 x_i =
  \begin{cases}
    \beta_0+(\beta_1 \times 1) = \beta_0+\beta_1  &amp; \quad \text{kui on naine}\\
    \beta_0+(\beta_1 \times 0) = \beta_0  &amp; \quad \text{kui on mees}
  \end{cases}
\]</span></p>
<p>Kui <span class="math inline">\(x_i\)</span> väärtus on <span class="math inline">\(0\)</span> (mehed), siis võrdub <span class="math inline">\(\hat{y_i}\)</span> vabaliikmega <span class="math inline">\(\beta_0\)</span> (sest <span class="math inline">\(\beta_1\)</span> korrutatakse läbi nulliga) ja kui <span class="math inline">\(x_i\)</span> väärtus on <span class="math inline">\(1\)</span> (naised), siis vabaliikme ja regressioonikoefitsiendi summaga <span class="math inline">\(\beta_0+\beta\)</span>.</p>
<p>Mida <span class="math inline">\(\hat{y}\)</span> antud juhul üldse tähistab? Pidevmuutujaga regressioonis tähistas see keskmist <span class="math inline">\(y\)</span>-i väärtust erinevate <span class="math inline">\(x\)</span> väärtuste korral. Ja siin täpselt samamoodi. Aga nüüd on meil ainult kaks <span class="math inline">\(x\)</span> väärtust ja <span class="math inline">\(\hat{y}\)</span> on vastavate gruppide (meeste ja naiste) keskmine <span class="math inline">\(y\)</span>.</p>
<p>Seega saame regressioonivõrrandiga väljenda binaarse tunnuse mõju sõltuva tunnuse keskmisele. Lihtsalt käsitleme ühte kategooriat nn <strong>referentskategooriana</strong> ja kodeerime selle <span class="math inline">\(0\)</span>’ks. Kui <span class="math inline">\(x\)</span> on <span class="math inline">\(0\)</span>, siis <span class="math inline">\(y\)</span> väärtus on võrdne vabaliikme väärtusega. Ja kui sõltumatu tunnuse väärtus muutub ühe ühiku võrra (ja rohkem ta ei saagi muutuda), siis on <span class="math inline">\(y\)</span> väärtus võrdne vabaliikme väärtus pluss regressioonikoefitsiendi väärtus. Regressioonikoefitsient (<span class="math inline">\(\beta_1\)</span>) eraldivõetuna on aga lihtsalt kahe grupi erinevus.</p>
<p>Defineerime mudeli:</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="2-lineaarne-regressioon.html#cb418-1" aria-hidden="true" tabindex="-1"></a>mudel2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb418-2"><a href="2-lineaarne-regressioon.html#cb418-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ sugu, data = piaac)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -974.0 -344.0 -122.7  198.1 2755.2 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1077.90      13.35   80.73   &lt;2e-16 ***
## suguNaine    -383.15      17.52  -21.86   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 545.8 on 3982 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.1072, Adjusted R-squared:  0.107 
## F-statistic:   478 on 1 and 3982 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Kuidas me eelneva valguses oma näidet siis tõlgendama peaksime?</p>
<p><em>Sugu</em> oli tekstiline tunnus. R saab aru, et tegemist on kategoriaalse tunnusega ja kodeerib selle sisemiselt ümber <span class="math inline">\(0\)</span>-ks ja <span class="math inline">\(1\)</span>-ks. Antud juhul määras ta kategooria <em>Naine</em> <span class="math inline">\(1\)</span>-ks ja kategooria <em>Mees</em> <span class="math inline">\(0\)</span>-ks. Kuna tegemist oli tekstilise tunnusega, siis lähtub R siin tähestikulisest järjekorrast. Ümberkodeeritud (dihhotomiseeritud) tunnuse nimeks on alati mitte-referentskategooria. Antud juhul siis <em>suguNaine</em>. Regressioonivõrrand oli järgmine:</p>
<p><span class="math display">\[\hat{y_i}=\beta_0+\beta x_i+\epsilon\]</span></p>
<p>kus</p>
<p><span class="math display">\[\begin{align}
x_{i} =
  \begin{cases}
    1  &amp; \quad \text{kui on naine}\\
    0  &amp; \quad \text{kui on mees}
  \end{cases}
\end{align}\]</span></p>
<p>Paneme mudeli tulemused sellesse võrrandisse:</p>
<p><span class="math display">\[\begin{align}
\text{keskmine sissetulek}&amp;=1077.90+(-383.15)\times \text{sugu}\\
&amp;=
  \begin{cases}
    1077.90-383.15\times 1 &amp; \quad \text{kui on naine}\\
    1077.90-383.15\times 0 &amp; \quad \text{kui on mees}
  \end{cases}\\
&amp;=
  \begin{cases}
    1077.90-383.15 &amp; \quad \text{kui on naine}\\
    1077.90-0 &amp; \quad \text{kui on mees}
  \end{cases}\\
&amp;=
  \begin{cases}
    694.75 &amp; \quad \text{kui on naine}\\
    1077.90 &amp; \quad \text{kui on mees}
  \end{cases}
\end{align}\]</span></p>
<p>Ehk siis meeste keskmine sissetulek on <span class="math inline">\(1077.9\)</span> eurot (vabaliige) ja naiste keskmine sissetulek on <span class="math inline">\(694.8\)</span> eurot (vabaliige + regressioonikoefitsient).</p>
<p>Naiste keskmine sissetulek on meeste omast <span class="math inline">\(383\)</span> euro võrra väiksem (regressioonikoefitsient). Erinevus on statistiliselt oluline, kuna <em>p</em>-väärtused nii koefitsiendi <em>t</em>-testi kui ka mudeli <em>F</em>-testi puhul olid olulisusnivool <span class="math inline">\(95\%\)</span> olulised (väiksemad kui <span class="math inline">\(0.05\)</span>).</p>
<p>Kui me paneme gruppide keskmised joonisele ja ühendame nad joonega, näeme, et selle joone tõus (<em>slope</em>) on võrdne regressioonikoefitsiendiga, täpselt samuti nagu pidevtunnusega regressioonis.</p>
<p><img src="01-regressioon_files/figure-html/reg-plot-6-1.png" width="672" /></p>
</div>
<div id="kolme-või-enama-kategooriaga-sõltumatu-tunnus" class="section level3 hasAnchor" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> Kolme või enama kategooriaga sõltumatu tunnus<a href="2-lineaarne-regressioon.html#kolme-või-enama-kategooriaga-sõltumatu-tunnus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Kusjuures me ei pea piirduma vaid binaarsete tunnustega. Aga kui kategooriaid on rohkem, tuleb meil nad binaarseks teha ehk dihhotomiseerida. Määratleme ühe kategooria referentskategooriana ja ülejäänud kategooriad kodeerime erinevates tunnustes <span class="math inline">\(1\)</span>’ks. Seega, kui meil on näiteks hariduse tunnus kolme kategooriaga (põhiharidus, keskharidus, kõrgharidus), peame määratlema ühe referentskategooria (näiteks põhiharidus) ja tegema kaks uut tunnust (vastavalt keskhariduse ja kõrghariduse kategooriatele):</p>
<p><span class="math display">\[ kesk_{i} =
  \begin{cases}
    1  &amp; \quad \text{kui inimene on keskharidusega}\\
    0  &amp; \quad \text{kui inimene ei ole keskharidusega}
  \end{cases}
\]</span></p>
<p><span class="math display">\[ korg_{i} =
  \begin{cases}
    1  &amp; \quad \text{kui inimene on kõrgharidusega}\\
    0  &amp; \quad \text{kui inimene ei ole kõrgaridusega}
  \end{cases}
\]</span></p>
<p>Nüüd saame iga inimese hariduse määratleda nende kahe tunnuse kaudu. Ehk siis inimene, kelle puhul <span class="math inline">\(kesk = 1\)</span> ja <span class="math inline">\(korg = 0\)</span>, on keskharidusega; inimene, kelle puhul <span class="math inline">\(kesk = 0\)</span> ja <span class="math inline">\(korg = 1\)</span>, on kõrgharidusega ja inimene, kelle puhul <span class="math inline">\(kesk = 0\)</span> ja <span class="math inline">\(korg = 0\)</span>, on põhiharidusega.</p>
<p><span class="math inline">\(y\)</span> väärtus kujuneb täpselt samamoodi nagu binaarse tunnuse puhul:</p>
<p><span class="math display">\[y_i=\beta_0+\beta_1 \times kesk_i+\beta_2 \times korg_i\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    \beta_0+\beta_1 \times 1+\beta_2 \times 0  &amp; \quad \text{keskharidusega}\\
    \beta_0+\beta_1 \times 0+\beta_2 \times 1  &amp; \quad \text{kõrgaridusega}\\
    \beta_0+\beta_1 \times 0+\beta_2 \times 0  &amp; \quad \text{põhiharidusega}
  \end{cases}\\
&amp;=
  \begin{cases}
    \beta_0+\beta_1  &amp; \quad \text{keskharidusega}\\
    \beta_0+\beta_2  &amp; \quad \text{kõrgaridusega}\\
    \beta_0  &amp; \quad \text{põhiharidusega}
  \end{cases}
\end{align}\]</span></p>
<p>Vaatame kuidas see kõik R-is välja näeb. Hindame hariduse (tunnus <em>haridustase</em>) mõju sissetulekule:</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="2-lineaarne-regressioon.html#cb420-1" aria-hidden="true" tabindex="-1"></a>mudel3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> haridustase, <span class="at">data =</span> piaac)</span>
<span id="cb420-2"><a href="2-lineaarne-regressioon.html#cb420-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ haridustase, data = piaac)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -868.3 -362.5 -145.2  187.1 2881.2 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        763.35      13.33  57.279   &lt;2e-16 ***
## haridustaseKõrge   217.23      19.06  11.400   &lt;2e-16 ***
## haridustaseMadal   -22.20      30.17  -0.736    0.462    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 567.1 on 3981 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.03631,    Adjusted R-squared:  0.03583 
## F-statistic:    75 on 2 and 3981 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>R sai jällegi ise aru, et <em>haridustase</em> on tekstiline tunnus ja dihotomiseeris selle automaatselt ära, tehes kaks uut tunnust: <em>haridustaseKõrge</em> (kus kõik kõrgharitud on kodeeritud <span class="math inline">\(1\)</span>-na ja kõik teised <span class="math inline">\(0\)</span>-na) ja <em>haridustaseMadal</em> (kus kõik madala haridustasemega on kodeeritud <span class="math inline">\(1\)</span>-na ja kõik teised <span class="math inline">\(0\)</span>-na). Referentskategooriaks võttis ta tähestiku järjekorras esimese kategooria <em>Keskmine</em> (kõik vaatlused, mille puhul nii <em>haridustaseKõrge</em> kui ka <em>haridustaseMadal</em> on <span class="math inline">\(0\)</span>-d, on keskmise haridustasemega).</p>
<p>Tulemuste interpreteerimine toimub samamoodi nagu binaarse tunnuse puhul. Vabaliige tähistab referentskategooria, ehk antud juhul keskmise haridustasemega inimeste, keskmist sissetulekut (<span class="math inline">\(763.35\)</span>), <em>haridustaseKõrge</em> regressioonikordaja tähistab kõrge haridustasemega inimeste keskmise sissetuleku erinevust ja <em>haridustaseMadal</em> madala haridustasemega inimeste keskmise sissetuleku erinevust referentskategooria ehk keskmise haridustasemega inimeste keskmisest sissetulekust (vabaliikmest).</p>
<p>Võrrandi kujul näeb tulem välja järgmine:
<span class="math display">\[y_i=\beta_0+\beta_1 \times korge_i+\beta_2 \times madal_i\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    763.35+217.23 \times 1+(-22.20) \times 0 &amp; \quad \text{kõrge haridustase}\\
    763.35+217.23 \times 0+(-22.20) \times 1 &amp; \quad \text{madal haridustase}\\
    763.35+217.23 \times 0+(-22.20) \times 0 &amp; \quad \text{keskmine haridustase}
  \end{cases}\\
&amp;=
  \begin{cases}
    763.35+217.23+0  &amp; \quad \text{kõrge haridustase}\\
    763.35+0-22.20  &amp; \quad \text{madal haridustase}\\
    763.35+0+0  &amp; \quad \text{keskmine haridustase}
  \end{cases}\\
&amp;=
  \begin{cases}
    980.58  &amp; \quad \text{kõrge haridustase}\\
    741.15  &amp; \quad \text{madal haridustase}\\
    763.35  &amp; \quad \text{keskmine haridustase}
  \end{cases}
\end{align}\]</span></p>
<p>Kui kategoriaalne sõltumatu tunnus on tekstiline (<em>character</em>), siis valib R referentskategooriaks tähestikuliselt esimese kategooria. Kui tunnus on faktortunnus (<em>factor</em>), siis valib R esimese faktortaseme. Faktortasemeid saame me aga muuta. Tihti tahame referentskategooria ise valida (näiteks kõige suurema grupi või grupi, mida on loogiline teistega võrrelda). Näiteks tahame haridustasemete puhul määrata referentskategooriaks põhihariduse. Selleks teeme tunnuse faktoriks ja määrame tasemete järjestuse nii, et madal haridustase oleks esimene:</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="2-lineaarne-regressioon.html#cb422-1" aria-hidden="true" tabindex="-1"></a><span class="co"># vaatame kõigepealt mis kategooriad tunnuses on</span></span>
<span id="cb422-2"><a href="2-lineaarne-regressioon.html#cb422-2" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(piaac<span class="sc">$</span>haridustase)</span></code></pre></div>
<pre><code>## [1] &quot;Keskmine&quot; &quot;Madal&quot;    &quot;Kõrge&quot;    NA</code></pre>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="2-lineaarne-regressioon.html#cb424-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Laeme forcats paketti, millega on mugav faktoritega toimetada</span></span>
<span id="cb424-2"><a href="2-lineaarne-regressioon.html#cb424-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(forcats)</span>
<span id="cb424-3"><a href="2-lineaarne-regressioon.html#cb424-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Kasutame funktsiooni fct_relevel()</span></span>
<span id="cb424-4"><a href="2-lineaarne-regressioon.html#cb424-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Meil on antud juhul vaja määrata ainult esimene tasand,</span></span>
<span id="cb424-5"><a href="2-lineaarne-regressioon.html#cb424-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  ülejäänud tulevad tähestiku järjekorras.</span></span>
<span id="cb424-6"><a href="2-lineaarne-regressioon.html#cb424-6" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb424-7"><a href="2-lineaarne-regressioon.html#cb424-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">haridustase_f =</span> <span class="fu">fct_relevel</span>(haridustase, <span class="st">&quot;Madal&quot;</span>))</span>
<span id="cb424-8"><a href="2-lineaarne-regressioon.html#cb424-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-9"><a href="2-lineaarne-regressioon.html#cb424-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Baas-R-is käiks faktori tegemine nii:</span></span>
<span id="cb424-10"><a href="2-lineaarne-regressioon.html#cb424-10" aria-hidden="true" tabindex="-1"></a><span class="co">#piaac$haridustase_f &lt;- factor(piaac$haridustase, </span></span>
<span id="cb424-11"><a href="2-lineaarne-regressioon.html#cb424-11" aria-hidden="true" tabindex="-1"></a><span class="co">#                              levels = c(&quot;Madal&quot;,&quot;Keskmine&quot;,&quot;Kõrge&quot;))</span></span>
<span id="cb424-12"><a href="2-lineaarne-regressioon.html#cb424-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-13"><a href="2-lineaarne-regressioon.html#cb424-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ja kui me nüüd regressiooni jooksutame, on referentsiks madal tase</span></span>
<span id="cb424-14"><a href="2-lineaarne-regressioon.html#cb424-14" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sissetulek <span class="sc">~</span> haridustase_f, <span class="at">data =</span> piaac))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ haridustase_f, data = piaac)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -868.3 -362.5 -145.2  187.1 2881.2 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             741.15      27.07  27.381  &lt; 2e-16 ***
## haridustase_fKeskmine    22.20      30.17   0.736    0.462    
## haridustase_fKõrge      239.43      30.30   7.902 3.54e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 567.1 on 3981 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.03631,    Adjusted R-squared:  0.03583 
## F-statistic:    75 on 2 and 3981 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Kui meil juba on faktortunnus, aga tahame selle tasemete järjekorda muuta, saame jälle kasutada käsku <code>fct_relevel()</code>. Muudame haridustaseme faktortunnuses kõrgema hariduse esimeseks tasemeks:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="2-lineaarne-regressioon.html#cb426-1" aria-hidden="true" tabindex="-1"></a>piaac<span class="sc">$</span>haridustase_f <span class="ot">&lt;-</span> <span class="fu">fct_relevel</span>(piaac<span class="sc">$</span>haridustase_f, <span class="st">&quot;Kõrge&quot;</span>)</span>
<span id="cb426-2"><a href="2-lineaarne-regressioon.html#cb426-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-3"><a href="2-lineaarne-regressioon.html#cb426-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Baas-R-is käiks see nii:</span></span>
<span id="cb426-4"><a href="2-lineaarne-regressioon.html#cb426-4" aria-hidden="true" tabindex="-1"></a><span class="co">#piaac$haridustase_f &lt;- relevel(piaac$haridustase_f, ref = &quot;Kõrge&quot;)</span></span>
<span id="cb426-5"><a href="2-lineaarne-regressioon.html#cb426-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-6"><a href="2-lineaarne-regressioon.html#cb426-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(numeracy <span class="sc">~</span> haridustase_f, <span class="at">data =</span> piaac))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = numeracy ~ haridustase_f, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -202.991  -26.446    2.328   28.800  150.020 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           289.2173     0.8172  353.93   &lt;2e-16 ***
## haridustase_fMadal    -40.8718     1.4011  -29.17   &lt;2e-16 ***
## haridustase_fKeskmine -21.0568     1.0944  -19.24   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 42.72 on 7583 degrees of freedom
##   (46 observations deleted due to missingness)
## Multiple R-squared:  0.1065, Adjusted R-squared:  0.1063 
## F-statistic: 451.9 on 2 and 7583 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="teie-kord">
<p>Ülesanne!</p>
<ul>
<li>Piaaci andmestikus on tunnus <em>meeldib_oppida</em>. Tehke see faktortunnuseks nii, et esimene kategooria oleks “Mõningal määral” (kategooriate nimed saate teada näiteks funnktsiooniga <code>unique(piaac$meeldib_oppida)</code>)</li>
<li>Tehke regressioonimudel, kus hindate õppimishimu mõju sissetulekule</li>
</ul>
</div>
</div>
</div>
<div id="mitmene-regressioon" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Mitmene regressioon<a href="2-lineaarne-regressioon.html#mitmene-regressioon" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Siiani oleme käsitlenud lineaarset regressiooni, kus sõltumatuid tunnuseid oli üks. Aga on võimalik lülitada ühte mudelisse ka mitu sõltumatut tunnust. Miks see hea peaks olema?</p>
<p>Valdavalt üritame välja selgitada (või tegelikult mingi teooria põhjal testida) mingi tunnuse kausaalset mõju teisele tunnusele (sõltumatu tunnuse mõju sõltuvale tunnusele). Kausaalsusel on aga teatud eeldused:</p>
<ol style="list-style-type: decimal">
<li>Tunnuste vaheline seos (seose olemasolu ei tähenda muidugi kohe põhjalikkust)<br />
</li>
<li>Ajaline järgnevus (vastupidi ei saaks ju kuidagi olla)<br />
</li>
<li>Alternatiivse seletuse/põhjuse kõrvaldamine (sõltuv tunnus võib olla sõltumatu tunnuse poolt mõjutatud läbi mõne muu tunnuse, st kaudselt)</li>
</ol>
<p>Mitmene regressioon võimaldabki meil testida sõltumatute tunnuste otsest mõju sõltuvale tunnusele, kontrollides samal ajal teiste mudelisse lülitatud sõltumatute tunnuste mõjude suhtes (hoides teisi tunnuseid konstantsetena). Regressioonivõrrand mitme sõltumatu tunnuse puhul on sarnane ühese regressiooni võrrandiga, välja arvatud siis sõltumatute tunnuste arv. Mudel <span class="math inline">\(y\)</span> prognoosimiseks <span class="math inline">\(p\)</span> sõltumatute tunnuste kaudu on väljendatav järgmiselt:</p>
<p><span class="math display">\[\begin{equation}  
y_{i}=\beta_{0}+\beta_{1}x_{i,1}+\beta_{2}x_{i,2}+\ldots+\beta_{p}x_{i,p}+\epsilon_{i}
\end{equation}\]</span></p>
<p>Kus:</p>
<p><span class="math inline">\(\beta_0\)</span> on vabaliige (ehk <span class="math inline">\(y\)</span> väärtus kui kõik sõltumatud tunnused on <span class="math inline">\(0\)</span>’id)</p>
<p><span class="math inline">\(\beta_1\)</span> regressioonikoeffitsient esimesele sõltumatule tunnusele <span class="math inline">\(x_1\)</span></p>
<p><span class="math inline">\(\beta_2\)</span> regressioonikoeffitsient teisele sõltumatule tunnusele <span class="math inline">\(x_2\)</span></p>
<p><span class="math inline">\(\beta_{p}\)</span> regressioonikoeffitsient tunnusele <span class="math inline">\(x_{p}\)</span></p>
<p><span class="math inline">\(\epsilon\)</span> on mudeli jääk igale vaatlusele</p>
<p><span class="math inline">\(\beta\)</span> coefitsinedid on leitud nii, et nendega kaalutud tunnuste väärtused minimeerivad <span class="math inline">\(\epsilon\)</span>’i ehk mudeli viga (kogu mudeli mõistes minimeerivad ruuthälvete summat). <span class="math inline">\(\beta\)</span> väärtus on tõlgendatav kui muutus <span class="math inline">\(y\)</span> väärtuses, kui vastava sõltumatu tunnuse väärtus muutub ühe ühiku võrra, hoides samal ajal teisi sõltumatuid tunnuseid konstantsetena. See tähendab, et koefitsientides on teiste tunnuste mõju arvesse võetud ja meie tulemused peegeldavad nn “puhast” mõju.</p>
<p>Mudeli defineerimisel R-is saame sõltumatuid tunnuseid lisada <code>+</code> märgi abil:</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="2-lineaarne-regressioon.html#cb428-1" aria-hidden="true" tabindex="-1"></a>mudel4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> numeracy <span class="sc">+</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb428-2"><a href="2-lineaarne-regressioon.html#cb428-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ numeracy + sugu, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1181.73  -323.46   -98.77   167.86  2813.48 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  140.7631    55.0470   2.557   0.0106 *  
## numeracy       3.3533     0.1915  17.509   &lt;2e-16 ***
## suguNaine   -365.0623    16.9196 -21.576   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 526 on 3981 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.171,  Adjusted R-squared:  0.1706 
## F-statistic: 410.7 on 2 and 3981 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Mitmese regressiooni tõlgendus on analoogne lihtsa regressiooni tõlgendusega. Võrrandi kujul on see väljendatav järgmiselt:</p>
<p><span class="math display">\[\hat{y}_{sissetulek}=\beta_0+\beta_1 \times numeracy + \beta_2 \times naine\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    \beta_0+\beta_1 \times numeracy + \beta_2 \times 1 =  &amp; \quad \text{naine}\\
    \beta_0+\beta_1 \times numeracy + \beta_2 \times 0 =  &amp; \quad \text{mees}
  \end{cases}\\
&amp;=
  \begin{cases}
    (\beta_0+\beta_2)+\beta_1 \times numeracy  &amp; \quad \text{naine}\\
    \beta_0+\beta_1 \times numeracy &amp; \quad \text{mees}
  \end{cases}\\
\end{align}\]</span></p>
<p>Vabaliige näitab kategoriaalse tunnuse referentskategooria (antud juhul mees) keskmist sõltuva tunnuse väärtust. Aga kuna nüüd on meil mudelis ka sõltumatu pidevtunnus, siis on see referentskategooria keskmine juhul, kui ka sõltumatu pidevtunnus on <span class="math inline">\(0\)</span>. Ehk siis meie näite puhul tähistab vabaliige (<span class="math inline">\(140.8\)</span>) meeste sissetulekut juhul kui nende matemaatilise kirjaoskuse skoor on <span class="math inline">\(0\)</span>. <em>suguNaine</em> regressioonikordaja näitab naiste sissetuleku erinevust meestest. See võtab arvesse ka matemaatilise kirjaoskuse skoori. Ehk siis kõikide matemaatilise kirjaoskuse väärtuste puhul on on naiste sissetulek <span class="math inline">\(365\)</span> eurot meestest madalam (st soo mõju on kontrollitud matemaatilise kirjaoskuse suhtes). <em>numeracy</em> regressioonikordaja näitab jällegi sissetuleku muutust (<span class="math inline">\(3.35\)</span>) kui matemaatiline kirjaoskus muutub ühe ühiku võrra. Kuna ka sugu on mudelis arvesse võetud, kehtib see muutus võrdselt nii naistele kui meestele (mõju on kontrollitud soo suhtes).</p>
<p>Vaatame, milliseks kujunevad mudeli järgi meeste ja naiste keskmised sissetulekud, kui nende <em>numeracy</em> skoor on 300.</p>
<p><span class="math display">\[\hat{y}_{sissetulek}=140.8+3.35 \times numeracy + (-365) \times naine\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    140.8+3.35 \times 300 + (-365) \times 1  &amp; \quad \text{naine}\\
    140.8+3.35 \times 300 + (-365) \times 0  &amp; \quad \text{mees}
  \end{cases}\\
&amp;=
  \begin{cases}
    (140.8-365)+3.35 \times 300  &amp; \quad \text{naine}\\
    140.8+3.35 \times 300 &amp; \quad \text{mees}
  \end{cases}\\
&amp;=
  \begin{cases}
    -224.2+1005  &amp; \quad \text{naine}\\
    140.8+1005 &amp; \quad \text{mees}
  \end{cases}\\
&amp;=
  \begin{cases}
    780.8  &amp; \quad \text{naine}\\
    1145.8 &amp; \quad \text{mees}
  \end{cases}
\end{align}\]</span></p>
<p>Mõnevõrra lihtsam on seda tulemust interpreteerida graafiliselt:</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="2-lineaarne-regressioon.html#cb430-1" aria-hidden="true" tabindex="-1"></a>piaac <span class="sc">%&gt;%</span> </span>
<span id="cb430-2"><a href="2-lineaarne-regressioon.html#cb430-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> numeracy, <span class="at">y =</span> sissetulek, <span class="at">color =</span> sugu))<span class="sc">+</span></span>
<span id="cb430-3"><a href="2-lineaarne-regressioon.html#cb430-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.1</span>, <span class="at">size =</span> <span class="fl">0.6</span>)<span class="sc">+</span></span>
<span id="cb430-4"><a href="2-lineaarne-regressioon.html#cb430-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fl">140.8</span>, <span class="at">slope =</span> <span class="fl">3.35</span>, <span class="at">color =</span> <span class="st">&quot;#972D15&quot;</span>, <span class="at">size =</span> <span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb430-5"><a href="2-lineaarne-regressioon.html#cb430-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fl">140.8</span><span class="dv">-365</span>, <span class="at">slope =</span> <span class="fl">3.35</span>, <span class="at">color =</span> <span class="st">&quot;#02401B&quot;</span>, <span class="at">size =</span> <span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb430-6"><a href="2-lineaarne-regressioon.html#cb430-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;Mees&quot;</span> <span class="ot">=</span> <span class="st">&quot;#972D15&quot;</span>, <span class="st">&quot;Naine&quot;</span> <span class="ot">=</span> <span class="st">&quot;#02401B&quot;</span>))<span class="sc">+</span></span>
<span id="cb430-7"><a href="2-lineaarne-regressioon.html#cb430-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()<span class="sc">+</span></span>
<span id="cb430-8"><a href="2-lineaarne-regressioon.html#cb430-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">override.aes =</span> <span class="fu">list</span>(<span class="at">size =</span> <span class="dv">2</span>, <span class="at">alpha =</span> <span class="dv">1</span>)))</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/reg-plot-7-1.png" width="672" /></p>
<p>Lihtsam võimalus seoseid graafiliselt esitada on kasutada paketist <code>interactions</code> funktsiooni <code>interaction_plot()</code>. See on küll mõeldud eelkõige koosmõjude plottimiseks, kuid toimib ka tavalisete seoste kujutamisel.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="2-lineaarne-regressioon.html#cb431-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(interactions)</span>
<span id="cb431-2"><a href="2-lineaarne-regressioon.html#cb431-2" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(mudel4, <span class="at">pred =</span> numeracy, <span class="at">modx =</span> sugu, <span class="at">colors =</span> <span class="fu">c</span>(<span class="st">&quot;#972D15&quot;</span>, <span class="st">&quot;#02401B&quot;</span>))</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div id="kaks-pidevat-sõltumatut-muutujat" class="section level3 hasAnchor" number="2.6.1">
<h3><span class="header-section-number">2.6.1</span> Kaks pidevat sõltumatut muutujat<a href="2-lineaarne-regressioon.html#kaks-pidevat-sõltumatut-muutujat" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vaatame ka olukorda, kus meil on kaks pidevat sõltumatut tunnust - matemaatiline kirjaoskus ja vanus:</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="2-lineaarne-regressioon.html#cb432-1" aria-hidden="true" tabindex="-1"></a>mudel5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek<span class="sc">~</span>numeracy<span class="sc">+</span>vanus, <span class="at">data =</span> piaac)</span>
<span id="cb432-2"><a href="2-lineaarne-regressioon.html#cb432-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ numeracy + vanus, data = piaac)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1036.6  -349.5  -128.9   178.7  2944.0 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  25.3372    67.3417   0.376    0.707    
## numeracy      3.4841     0.2033  17.137  &lt; 2e-16 ***
## vanus        -3.2210     0.7138  -4.512 6.59e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 554.5 on 3981 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.07879,    Adjusted R-squared:  0.07833 
## F-statistic: 170.3 on 2 and 3981 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Tõlgendame seda järmiselt:</p>
<ol style="list-style-type: decimal">
<li>Kui matemaatiline kirjaoskus tõuseb ühe punkti võrra, siis sissetulek tõuseb <span class="math inline">\(3.48\)</span> euro võrra, hoides vanust konstantsena (st see seos kehtib kõikide vanuste jaoks).<br />
</li>
<li>Kui vanus tõuseb ühe aasta võrra, siis sissetulek langeb <span class="math inline">\(3.2\)</span> euro võrra, hoides matemaatilist kirjaoskust konstantsena (st see seos kehtib kogu matemaatilise kirjaoskuse skaala ulatuses).<br />
</li>
<li>Juhul kui nii vanus oleks <span class="math inline">\(0\)</span> aastat ja matemaatiline kirjaoskus oleks <span class="math inline">\(0\)</span> punkti, oleks sissetulek <span class="math inline">\(25.3\)</span> eurot (kuna selline olukord on suhteliselt võimatu, siis me sellistel puhkudel vabaliiget ei interpreteeri).</li>
</ol>
<p>Et taolisest mudelist paremini aru saada võime kasutada 3D punktdiagrammi</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="2-lineaarne-regressioon.html#cb434-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(car)</span></span>
<span id="cb434-2"><a href="2-lineaarne-regressioon.html#cb434-2" aria-hidden="true" tabindex="-1"></a><span class="co">#scatter3d(piaac$numeracy,piaac$sissetulek, piaac$vanus)</span></span></code></pre></div>
<div class="teie-kord">
<p>Ülesanne!</p>
<ul>
<li>Looge regressioonimudel, millega hindate <em>numeracy</em>, <em>vanus</em>, <em>sugu</em> ja <em>haridustase</em> mõju sissetulekule.</li>
<li>Milliste tunnuste mõju sissetulekule on statistiliselt oluline?</li>
<li>Esitage vanuse ja soo mõju sissetulekule graafiliselt.</li>
</ul>
</div>
</div>
</div>
<div id="koosmõjud" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Koosmõjud<a href="2-lineaarne-regressioon.html#koosmõjud" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Eelnevas näites vaatasime sissetuleku sõltuvust matemaatilise kirjaoskuse tasemest soo lõikes, ja nägime, et kui lisame mudelisse soo tunnuse, siis saame klasside kohta eraldi regressioonijooned. Kuid need regressioonijooned olid paralleelsed, mis tähendab et nii meeste kui naiste hulgas oli matemaatilise kirjaoskuse mõju sissetulekule mudeli järgi sama. Kuid kas see on alati väga realistlik eeldus? Võib ju vabalt olla, et see seos erineb soo lõikes.</p>
<p>Kui me arvame, et see võib nii olla, st sõltumatu tunnuse mõju sõltuvale tunnusele sõltub omakorda mingist muust tunnusest, saame mudelisse lisada nende kahe tunnuse koosmõju (interaktsiooni). Selleks peame moodustame uue tunnuse, mis tuleneb nende tunnuste, mille suhtes me koosmõju hinnata tahame, korrutisest. Kui me nüüd selle uue tunnuse mudelisse kaasame, siis hindame sellele ka regressioonikoefitsiendi. Regressioonivõrrand pidevtunnuse ja kategoriaalse tunnuse koosmõjuga näeks välja nii:</p>
<p><span class="math display">\[\hat{y}_{sissetulek}=\beta_0+\beta_1 \times numeracy + \beta_2 \times naine + \beta_3 \times naine \times numeracy \]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    \beta_0+\beta_1 \times numeracy + \beta_2 \times 1 + \beta_3 \times 1 \times numeracy  &amp; \quad \text{naised}\\
    \beta_0+\beta_1 \times numeracy + \beta_2 \times 0 + \beta_3 \times 0 \times numeracy &amp; \quad \text{mehed}
  \end{cases}\\
&amp;=
  \begin{cases}
    (\beta_0+\beta_2)+(\beta_1+\beta_3) \times numeracy  &amp; \quad \text{naised}\\
    \beta_0+\beta_1 \times numeracy &amp; \quad \text{mehed}
  \end{cases}
\end{align}\]</span></p>
<p>Mis siin nüüd siis toimub? Meeste keskmine sissetulek on, nagu varasemaltki, defineeritud vabaliikme ja <span class="math inline">\(\beta_1\)</span> regressioonikoefitsiendiga (ülejäänud kaks koefitsienti lähevad meeste jaoks <span class="math inline">\(0\)</span>-ks, kuna <em>naine</em> tunnus on nende jaoks <span class="math inline">\(0\)</span>). Naistel on aga lisaks veel kaks koefitsienti. <span class="math inline">\(\beta_2\)</span>, mis, nagu varasemaltki, kirjeldab naiste vabaliikme erinevust meeste vabaliikmest, ning siis veel <span class="math inline">\(\beta_3\)</span>, mis kirjeldab naiste regressioonisirge erinevust meeste regressioonisirgest. Koosmõjudega mudelis on naiste <em>numeracy</em> koefitsient <span class="math inline">\(\beta_1+\beta_3\)</span> (sest <span class="math inline">\(\beta_1 \times numeracy + \beta_3 \times numeracy = (\beta_1+\beta_3) \times numeracy\)</span>).</p>
<p>R-is saame koosmõjudega mudeli defineerida kui kasutame tunnuste vahel, mille koosmõjusid tahame kodelleerida, <span class="math inline">\(*\)</span> märki. Ehk kui tahame matemaatilise kirjaoskuse ja soo koosmõju, siis peame defineerima mudeli nii:</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="2-lineaarne-regressioon.html#cb435-1" aria-hidden="true" tabindex="-1"></a>mudel8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> numeracy <span class="sc">*</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb435-2"><a href="2-lineaarne-regressioon.html#cb435-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel8)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ numeracy * sugu, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1213.35  -322.79   -99.79   166.87  2802.32 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          28.4609    79.7161   0.357   0.7211    
## numeracy              3.7552     0.2815  13.340   &lt;2e-16 ***
## suguNaine          -157.9875   107.6870  -1.467   0.1424    
## numeracy:suguNaine   -0.7476     0.3840  -1.947   0.0516 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 525.8 on 3980 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.1718, Adjusted R-squared:  0.1712 
## F-statistic: 275.2 on 3 and 3980 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="2-lineaarne-regressioon.html#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sama tulemuse saaksime, kui kirjutaksime:</span></span>
<span id="cb437-2"><a href="2-lineaarne-regressioon.html#cb437-2" aria-hidden="true" tabindex="-1"></a><span class="co">#lm(numeracy ~ literacy + sugu + literacy:sugu, data = piaac)</span></span></code></pre></div>
<p>Mida saadud koefitsiendid meile ütlevad?</p>
<ul>
<li>Vabaliige on meeste, kelle <em>numeracy</em> skoor on 0, keskmine sissetulek.<br />
</li>
<li><em>numeracy</em> koefitsient näitab palju muutub meeste keskmine sissetulek iga lisanduva matemaatilise kirjaoskuse punktiga.<br />
</li>
<li><em>suguNaine</em> koefitsient näitab palju erineb naiste sissetulek meeste omast kui nende mõlema <em>numeracy</em> skoor on 0.<br />
</li>
<li><em>numeracy:suguNaine</em> koefitsient näitab naiste <em>numeracy</em> koefitsiendi erinevust meeste <em>numeracy</em> koefitsiendist (naiste puhul on sissetuleku kasv iga lisanduva matemaatilise kirjaoskuse punkti puhul 0,7 euro võrra väiksem kui meestel, ehk siis nende regressioonisirge on laugem).</li>
</ul>
<p>Nagu näeme, siis koefitsiendid iseseisvalt on suhteliselt keeruliselt tõlgendatavad ja osaliselt ka sisutud, kuna <em>numeracy</em> skoor ei saa 0 olla (tunnuseid transformeerides saame nad tegelikult natukene interpreteeritavamateks teha, kuid sellest natuke hiljem).</p>
<p>Parema pildi saame, kui lihtsutame regressioonivõrrandit. Koosmõjudega mudeli vabaliikmed ja regressioonikoefitsiendid kujunevad järgmiselt:</p>
<p><span class="math display">\[\hat{y}_{sissetulek}=\beta_0+\beta_1 \times numeracy + \beta_2 \times naine + \beta_3 \times naine \times numeracy\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    28.5+3.8 \times numeracy + (-157) \times 1 + (-0.7) \times 1 \times numeracy &amp; \quad \text{naised}\\
    28.5+3.8 \times numeracy + (-157) \times 0 + (-0.7) \times 0 \times numeracy &amp; \quad \text{mehed}
  \end{cases}\\
&amp;=
  \begin{cases}
    (28.5-157)+(3.8-0.7) \times numeracy  &amp; \quad \text{naised}\\
    28.5+3.8 \times numeracy &amp; \quad \text{mehed}
  \end{cases}\\
&amp;=
  \begin{cases}
    -128.5+3.1 \times numeracy  &amp; \quad \text{naised}\\
    28.5+3.8 \times numeracy &amp; \quad \text{mehed}
  \end{cases}
\end{align}\]</span></p>
<p>Seega selles mudelis erinevad kategoriaalse tunnuse lõikes nii vabaliikme väärtused kui ka regressioonisirge tõusud. Kui me nüüd selle mudeli tulemused graafikule paneme, siis näeme, et regressioonisirged ei ole enam paralleelsed. Mida suurem on matemaatilise kirjaoskuse tase, seda suurem on erinevus meeste ja naiste sissetulekutes.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="2-lineaarne-regressioon.html#cb438-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(mudel8, <span class="at">pred =</span> numeracy, <span class="at">modx =</span> sugu,  <span class="at">colors =</span>  <span class="fu">c</span>(<span class="st">&quot;#972D15&quot;</span>, <span class="st">&quot;#02401B&quot;</span>))</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/reg-plot-8-1.png" width="672" /></p>
<p>Kõige parem ongi interaktsioonidega mudeleid graafiliselt vaadata.</p>
<div id="koosmõjud-kategoriaalsete-tunnuste-puhul" class="section level3 hasAnchor" number="2.7.1">
<h3><span class="header-section-number">2.7.1</span> Koosmõjud kategoriaalsete tunnuste puhul<a href="2-lineaarne-regressioon.html#koosmõjud-kategoriaalsete-tunnuste-puhul" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Enne oli juttu, et kahe kategoriaalse sõltumatu tunnusega mudel ilma koosmõjudeta pole väga mõistlik. Vaatame nüüd kuidas see koosmõjudega välja näeks:</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="2-lineaarne-regressioon.html#cb439-1" aria-hidden="true" tabindex="-1"></a>mudel9 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> sugu <span class="sc">*</span> haridustase, <span class="at">data =</span> piaac)</span>
<span id="cb439-2"><a href="2-lineaarne-regressioon.html#cb439-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel9)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ sugu * haridustase, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1126.25  -311.40   -99.32   163.85  2639.98 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                 1004.53      17.95  55.967   &lt;2e-16 ***
## suguNaine                   -458.80      24.76 -18.533   &lt;2e-16 ***
## haridustaseKõrge             252.60      28.59   8.836   &lt;2e-16 ***
## haridustaseMadal             -73.55      37.63  -1.955   0.0507 .  
## suguNaine:haridustaseKõrge    50.69      36.65   1.383   0.1667    
## suguNaine:haridustaseMadal    10.76      56.52   0.190   0.8491    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 526.1 on 3978 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.1715, Adjusted R-squared:  0.1705 
## F-statistic: 164.7 on 5 and 3978 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Kui mudelis on ainult kategoorilised tunnused, siis on selle tõlgendamine suhteliselt lihtne. Sellisest mudelist saame välja lugeda kõikide gruppide ristlõigete (kõrge haridustasemega naised, kõrge haridustasemega mehed jne) keskmised või täpsemini kõikide gruppide ristlõigete erinevused referentsgrupist:</p>
<ul>
<li>Vabaliige on referentsgrupi ehk keskmise haridustasemega meeste keskmine sissetulek.<br />
</li>
<li><em>suguNaine</em> on keskmise keskmise haridustasemega naiste erinevus referentsgrupist.</li>
<li><em>haridustaseKõrge</em> on kõrge haridustasemega meeste erinevus referentsgrupist.</li>
<li><em>haridustaseMadal</em> on madala haridustasemega meeste erinevus referentsgrupist.</li>
<li><em>suguNaine:haridustaseKõrge</em> on kõrge haridustasemega naiste erinevus keskmise haridustasemega naistest.</li>
<li><em>suguNaine:haridustaseMadal</em> on madala haridustasemega naiste erinevus keskmise haridustasemega naistest.</li>
</ul>
<p>Arvutame näiteks välja kõrge haridustasemega (<em>koh</em>) naiste ja madala haridustasemega (<em>mh</em>) meeste keskmised matemaatilise lugemisoskuse skoorid:</p>
<p><span class="math display">\[\hat{y}_{sissetulek}=\beta_0+\beta_1 \times naine + \beta_2 \times koh + \beta_3 \times mh + \beta_4 \times naine \times koh + \beta_5 \times naine \times mh\]</span></p>
<p><span class="math display">\[\begin{align}
&amp;=
  \begin{cases}
    1004.5+(-458.8) \times 1 + 252.60 \times 1 + (-73.55) \times 0 + 50.69 \times 1 + 10.76 \times 0 &amp; \quad \text{kõrge haridustasemega naised}\\
    1004.5+(-458.8) \times 0 + 252.60 \times 0 + (-73.55) \times 1 + 50.69 \times 0 + 10.76 \times 0 &amp; \quad \text{madala haridustasemega mehed}
  \end{cases}\\
&amp;=
  \begin{cases}
    1004.5+(-458.8) + 252.60 + 50.69 &amp; \quad \text{kõrge haridustasemega naised}\\
    1004.5 + (-73.55) &amp; \quad \text{madala haridustasemega mehed}
  \end{cases}\\
&amp;=
  \begin{cases}
    849 &amp; \quad \text{kõrge haridustasemega naised}\\
    931 &amp; \quad \text{madala haridustasemega mehed}
  \end{cases}
\end{align}\]</span></p>
<p>Kõige mugavam on taolist mudelit interpreteerida aga jällegi graafiliselt (kasutame paketi <code>interactions</code> funktsiooni <code>cat_plot()</code>):</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="2-lineaarne-regressioon.html#cb441-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat_plot</span>(mudel9, <span class="at">pred =</span> haridustase, <span class="at">modx =</span> sugu, <span class="at">colors =</span>  <span class="fu">c</span>(<span class="st">&quot;#972D15&quot;</span>, <span class="st">&quot;#02401B&quot;</span>))</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<div class="teie-kord">
<p>Ülesanne!</p>
<ul>
<li>Looge koosmõjuga regressioonimudel, millega hindate soo ja laste olemasolu mõju sissetulekule.</li>
<li>Esitage koosmõjud graafikul (<code>cat_plot()</code> abiga)</li>
</ul>
</div>
</div>
</div>
<div id="mudelite-võrdlemine" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Mudelite võrdlemine<a href="2-lineaarne-regressioon.html#mudelite-võrdlemine" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Milline on hea mudel? See peaks muidugi seletama võimalikult palju sõltuva tunnuse varieeruvusest. Samas peaks see olema ka võimalikult ökonoomne, st see peaks sisaldama ainult tunnuseid, mis mudelit oluliselt paremaks teevad. Siin on rõhk sõnal “oluliselt”. Iga lisanduv tunnus teeb mudeli mingil määral paremaks, kuid see paranemine võib olla mikroskoopiline. Kuidas siis hinnata, kas mudel <span class="math inline">\(n+1\)</span> tunnusega on oluliselt parem kui <span class="math inline">\(n\)</span> tunnusega mudel?</p>
<p>Me saame vaadata lisanduva tunnuse standardviga, <em>t</em>-väärtust ja sellega seonduvat <em>p</em>-väärtust. Kuid nagu enne jutuks oli, testib see ainult konkreetse koefitsiendi erinevust nullist. Meid aga huvitab kogu mudeli kvaliteet. Võimalus on ka võrrelda mudelite <span class="math inline">\(R^2\)</span> väärtusi, kuid need on pigem kirjeldavad, ega anna meile indikatsiooni sellest kas üks väärtus on oluliselt parem kui teine.</p>
<p>Erinevate mudelite statistiliselt olulist erinevust saame testida hii-ruut testiga kasutades <code>anova()</code> funktsiooni. Seda saab teha ainult siis kui mudelid on omavehl seotud (<em>nested</em>), st keerukam (rohkemate tunnustega) mudel peab sisdaldama kõiki lihtsama mudeli tunnuseid.</p>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="2-lineaarne-regressioon.html#cb442-1" aria-hidden="true" tabindex="-1"></a>mudel_test1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(numeracy <span class="sc">~</span> literacy, <span class="at">data =</span> piaac)</span>
<span id="cb442-2"><a href="2-lineaarne-regressioon.html#cb442-2" aria-hidden="true" tabindex="-1"></a>mudel_test2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(numeracy <span class="sc">~</span> literacy <span class="sc">+</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb442-3"><a href="2-lineaarne-regressioon.html#cb442-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mudel_test1, mudel_test2, <span class="at">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: numeracy ~ literacy
## Model 2: numeracy ~ literacy + sugu
##   Res.Df     RSS Df Sum of Sq  Pr(&gt;Chi)    
## 1   7584 4848657                           
## 2   7583 4734885  1    113772 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Tõlgendame jällegi testi <em>p</em>-väärtust. Kui see on väiksem kui <span class="math inline">\(0.05\)</span> (usaldusnivool <span class="math inline">\(95\%\)</span>), siis võime järeldada, et mudelid on oluliselt erinevad, mis tähendab omakorda, et lisatud tunnus tõstis mudeli selgitusvõimet olulisel määral.</p>
</div>
<div id="regressioonimudeli-eeldused" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Regressioonimudeli eeldused<a href="2-lineaarne-regressioon.html#regressioonimudeli-eeldused" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Nagu iga meetodi puhul, on ka lineaarsel regressioonanalüüsil rida eeldusi, mis peavad olema täidetud, et analüüsist korrektseid järeldusi oleks võimalik teha.</p>
<ol style="list-style-type: decimal">
<li><p>Kõige olulisem eeldus on <strong>mudeli valiidsus</strong>. See tähendab, et mudel peab vastama uurimisküsimusele. Täpsemalt sõltuv tunnus peab adekvaatselt kajastama uuritavat fenomeni, mudelisse peaksid olema kaasatud kõik olulised sõltumatud tunnused ja mudel peaks olema üldistatav populatsioonile mille kohta järeldusi teha tahsetakse.</p></li>
<li><p>Statistiliselt kõige olulisem eeldus on <strong>lineaarne suhe sõltuva ja sõltumatu(te) tunnuse vahel</strong>. Kõrvaloleval joonisel on esitatud neli andmestikku, mille regressioonisirged on identsed (<span class="math inline">\(y=3+0.5x\)</span>). Tegelikult on identsed ka kõik muud andmete statistilised omadused (<span class="math inline">\(x\)</span>’i keskmine, <span class="math inline">\(y\)</span>’i keskmine, <span class="math inline">\(x\)</span>’i dispersioon, <span class="math inline">\(y\)</span>’i dispersioon ja ka korrelatsioon). Ometi on visuaalselt näha, et kõik seosed on väga erinevad. Seega peaks regressioonanalüüsi (või tegelikult ükskõik mis analüüsi) puhul olema alati esimene samm neid graafiliselt uurida. Kui tunnuste vaheline seos ei ole lineaarne, piisab mõnel juhul interaktsioonide lisamisest või tunnuste mittelineaarsest transformeerimisest. Kui seos on eksponentsiaalne, siis võib kaaluda <em>log</em>-transformatsiooni. Kui seos on paraboolne, siis võib kaaluda ruutu tõstetud tunnuse lisamist ehk polünoomset regressiooni (<span class="math inline">\(y = \beta_0+\beta_1x+\beta_2x^2\)</span>). Taoliste transformatsioonide juures peab meeles pidama, et koos nendega muutub ka mudeli tõlgendus.</p></li>
</ol>
<div class="figure"><span style="display:block;" id="fig:anscombe"></span>
<p class="caption">
Joonis 2.4: Anscombe kvartett
</p>
<img src="01-regressioon_files/figure-html/anscombe-1.png" alt="Anscombe kvartett" width="672" />
</div>
<ol start="3" style="list-style-type: decimal">
<li><strong>Jääkide sõltumatus</strong>. Ühe vaatluse jäägid ei tohiks olla korreleeritud teise vaatluse jääkidega. Selline olukord võib tekkida näiteks siis kui mudelist on välja jäänud mingi oluline tunnus (ühe tunnuse regressiooni puhul on see muidugi vaid hüpoteetiline olukord), näiteks hindame õpilaste testiskoore lähtuvalt nende õppimisele kulunud ajast, kuid ei arvesta, et õpilased tulevad erinevatest koolidest, kus võib olla erinev õppetase. Seega õpilaste tulemused ei ole enam sõltumatud, vaid sõltuvad koolist. Regressioonikoefitsientide standardvigade arvutamisel lähtutakse eeldusest, et jäägid on sõltumatud. Kui jäägid on korreleeritud, siis võib juhtuda, et me alahindame standardvigade suurust ehk siis oleme oma tulemustes ülemäära kindlad (usaldusintervallid ning <em>p</em>-väärtused tulevad liialt väikesed) ning võime näha seoseid seal kus neid tegelikult ei ole. Lahenduseks võiks olla puuduolevate tunnuste lisamine mudelisse (konkrteetse näite puhul kooli tunnus), mitmetasandiline mudel (seda vaatame hiljem) või klasterdatud standardvead (<em>clustered standard errors</em> või ka <em>cluster-robust standard errors</em>).</li>
</ol>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="2-lineaarne-regressioon.html#cb444-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Clustered standard errors</span></span>
<span id="cb444-2"><a href="2-lineaarne-regressioon.html#cb444-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb444-3"><a href="2-lineaarne-regressioon.html#cb444-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Eeldame, et valim on klasterdatud haridusvaldkonna alusel</span></span>
<span id="cb444-4"><a href="2-lineaarne-regressioon.html#cb444-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Defineerime regressioonimudeli </span></span>
<span id="cb444-5"><a href="2-lineaarne-regressioon.html#cb444-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  (jätame välja kõik vaatlused, kus haridusvaldkond on NA)</span></span>
<span id="cb444-6"><a href="2-lineaarne-regressioon.html#cb444-6" aria-hidden="true" tabindex="-1"></a>mudel6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(numeracy <span class="sc">~</span> literacy <span class="sc">*</span> sugu, </span>
<span id="cb444-7"><a href="2-lineaarne-regressioon.html#cb444-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> piaac[<span class="sc">!</span><span class="fu">is.na</span>(piaac<span class="sc">$</span>hvaldkond),])</span>
<span id="cb444-8"><a href="2-lineaarne-regressioon.html#cb444-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb444-9"><a href="2-lineaarne-regressioon.html#cb444-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb444-10"><a href="2-lineaarne-regressioon.html#cb444-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Klasterdatud standardvigade arvutamiseks kasutame jälle sandwitch paketti ja</span></span>
<span id="cb444-11"><a href="2-lineaarne-regressioon.html#cb444-11" aria-hidden="true" tabindex="-1"></a><span class="co"># selle funktsiooni vcovCL()</span></span>
<span id="cb444-12"><a href="2-lineaarne-regressioon.html#cb444-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sandwich)</span>
<span id="cb444-13"><a href="2-lineaarne-regressioon.html#cb444-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb444-14"><a href="2-lineaarne-regressioon.html#cb444-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb444-15"><a href="2-lineaarne-regressioon.html#cb444-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Robustsete standardvigade jaoks tuleb meil arvutada uus </span></span>
<span id="cb444-16"><a href="2-lineaarne-regressioon.html#cb444-16" aria-hidden="true" tabindex="-1"></a><span class="co">#  &#39;klasterdatud&#39; koefitsientide variatsiooni-kovariatsiooni maatriks ehk nn </span></span>
<span id="cb444-17"><a href="2-lineaarne-regressioon.html#cb444-17" aria-hidden="true" tabindex="-1"></a><span class="co">#  Clustered Covariance Matrix. sandwitch paketis</span></span>
<span id="cb444-18"><a href="2-lineaarne-regressioon.html#cb444-18" aria-hidden="true" tabindex="-1"></a><span class="co">#  on selleks funktsioon vcovCL(). Peame selles lisaks mudeliobjektile</span></span>
<span id="cb444-19"><a href="2-lineaarne-regressioon.html#cb444-19" aria-hidden="true" tabindex="-1"></a><span class="co">#  määrama ka klastritunnuse</span></span>
<span id="cb444-20"><a href="2-lineaarne-regressioon.html#cb444-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb444-21"><a href="2-lineaarne-regressioon.html#cb444-21" aria-hidden="true" tabindex="-1"></a><span class="fu">vcovCL</span>(mudel6, <span class="at">cluster =</span> <span class="sc">~</span>hvaldkond) <span class="sc">%&gt;%</span> </span>
<span id="cb444-22"><a href="2-lineaarne-regressioon.html#cb444-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">diag</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb444-23"><a href="2-lineaarne-regressioon.html#cb444-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>()</span></code></pre></div>
<pre><code>##        (Intercept)           literacy          suguNaine literacy:suguNaine 
##         7.69411746         0.02019249         5.63277113         0.01773446</code></pre>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="2-lineaarne-regressioon.html#cb446-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Et neid koos koefitsientide ja vastavate testidega kuvada, võime kasutada</span></span>
<span id="cb446-2"><a href="2-lineaarne-regressioon.html#cb446-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  jällegi lmtest paketi funktsiooni coeftest()</span></span>
<span id="cb446-3"><a href="2-lineaarne-regressioon.html#cb446-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(mudel6, <span class="at">vcov. =</span> <span class="fu">vcovCL</span>(mudel6, <span class="at">cluster =</span> <span class="sc">~</span>hvaldkond))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                     Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)        35.718804   7.694117  4.6424 3.503e-06 ***
## literacy            0.872964   0.020192 43.2321 &lt; 2.2e-16 ***
## suguNaine           5.006361   5.632771  0.8888  0.374143    
## literacy:suguNaine -0.046464   0.017734 -2.6200  0.008812 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="4" style="list-style-type: decimal">
<li><strong>Jääkide dispersiooni homogeensus</strong> (<em>homoscedasticity</em>). Jäägid peaksid hinnatud väärtuste lõikes olema homogeense ja konstantse variatiivsusega, st ühtlaselt jaotunud kõikide <span class="math inline">\(\hat{y}\)</span> väärtuste ümber. Selle eelduse rikkumine mõjutab eelkõige standardvigu (need ei kehti enam kõikidele <span class="math inline">\(\hat{y}\)</span> väärtustele ühtlaselt) ja seeläbi loomulikult ka usaldusintervalle ning <em>p</em>-väärtusi. Lahenduseks võivad olla nn robustsed standardvead (<em>robust standard errors</em>), mis võtavad varieeruvuse erinevust arvesse, või siis jällegi tunnuste transformeerimine.</li>
</ol>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="2-lineaarne-regressioon.html#cb448-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Robust standard errors</span></span>
<span id="cb448-2"><a href="2-lineaarne-regressioon.html#cb448-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb448-3"><a href="2-lineaarne-regressioon.html#cb448-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Defineerime regressioonimudeli </span></span>
<span id="cb448-4"><a href="2-lineaarne-regressioon.html#cb448-4" aria-hidden="true" tabindex="-1"></a>mudel6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(numeracy <span class="sc">~</span> literacy <span class="sc">*</span> sugu, </span>
<span id="cb448-5"><a href="2-lineaarne-regressioon.html#cb448-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> piaac)</span>
<span id="cb448-6"><a href="2-lineaarne-regressioon.html#cb448-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb448-7"><a href="2-lineaarne-regressioon.html#cb448-7" aria-hidden="true" tabindex="-1"></a><span class="co"># summary() funktsiooniga saame kätte tavalised standardvead</span></span>
<span id="cb448-8"><a href="2-lineaarne-regressioon.html#cb448-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel6)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = numeracy ~ literacy * sugu, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -102.441  -16.551   -0.094   16.867   88.714 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        36.129029   2.620050  13.789  &lt; 2e-16 ***
## literacy            0.871523   0.009417  92.543  &lt; 2e-16 ***
## suguNaine           4.596729   3.619797   1.270 0.204164    
## literacy:suguNaine -0.044937   0.012972  -3.464 0.000535 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 24.97 on 7582 degrees of freedom
##   (46 observations deleted due to missingness)
## Multiple R-squared:  0.6948, Adjusted R-squared:  0.6946 
## F-statistic:  5753 on 3 and 7582 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="2-lineaarne-regressioon.html#cb450-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Robustsete standardvigade arvutamiseks kasutame sandwitch paketti</span></span>
<span id="cb450-2"><a href="2-lineaarne-regressioon.html#cb450-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  ja nende kuvamiseks lmtest paketti</span></span>
<span id="cb450-3"><a href="2-lineaarne-regressioon.html#cb450-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sandwich)</span>
<span id="cb450-4"><a href="2-lineaarne-regressioon.html#cb450-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb450-5"><a href="2-lineaarne-regressioon.html#cb450-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb450-6"><a href="2-lineaarne-regressioon.html#cb450-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Robustsete standardvigade jaoks tuleb meil arvutada uus </span></span>
<span id="cb450-7"><a href="2-lineaarne-regressioon.html#cb450-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  &#39;robustne&#39; koefitsientide variatsiooni-kovariatsiooni maatriks ehk nn </span></span>
<span id="cb450-8"><a href="2-lineaarne-regressioon.html#cb450-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  Heteroscedasticity-Consistent Covariance Matrix. sandwitch paketis</span></span>
<span id="cb450-9"><a href="2-lineaarne-regressioon.html#cb450-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  on selleks funktsioon vcovHC().</span></span>
<span id="cb450-10"><a href="2-lineaarne-regressioon.html#cb450-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb450-11"><a href="2-lineaarne-regressioon.html#cb450-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Variatsiooni-kovariatsiooni maatriksi diagonaalis on koefitsientide </span></span>
<span id="cb450-12"><a href="2-lineaarne-regressioon.html#cb450-12" aria-hidden="true" tabindex="-1"></a><span class="co">#  dispersioonid (variance). Ruutjuur dispersioonist annab koefitsiendi </span></span>
<span id="cb450-13"><a href="2-lineaarne-regressioon.html#cb450-13" aria-hidden="true" tabindex="-1"></a><span class="co">#  standardhälbe, mis on ongi pareameetri standardviga</span></span>
<span id="cb450-14"><a href="2-lineaarne-regressioon.html#cb450-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Seega saame robustsed standardvead kätte nii:</span></span>
<span id="cb450-15"><a href="2-lineaarne-regressioon.html#cb450-15" aria-hidden="true" tabindex="-1"></a><span class="fu">vcovHC</span>(mudel6) <span class="sc">%&gt;%</span> </span>
<span id="cb450-16"><a href="2-lineaarne-regressioon.html#cb450-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">diag</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb450-17"><a href="2-lineaarne-regressioon.html#cb450-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>()</span></code></pre></div>
<pre><code>##        (Intercept)           literacy          suguNaine literacy:suguNaine 
##        2.788735004        0.009897618        3.831308067        0.013555193</code></pre>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="2-lineaarne-regressioon.html#cb452-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Et neid koos koefitsientide ja vastavate testidega kuvada, võime kasutada</span></span>
<span id="cb452-2"><a href="2-lineaarne-regressioon.html#cb452-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  lmtest paketi funktsiooni coeftest()</span></span>
<span id="cb452-3"><a href="2-lineaarne-regressioon.html#cb452-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coeftest</span>(mudel6, <span class="at">vcov. =</span> <span class="fu">vcovHC</span>(mudel6))</span></code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                      Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)        36.1290294  2.7887350 12.9553 &lt; 2.2e-16 ***
## literacy            0.8715229  0.0098976 88.0538 &lt; 2.2e-16 ***
## suguNaine           4.5967288  3.8313081  1.1998 0.2302621    
## literacy:suguNaine -0.0449372  0.0135552 -3.3151 0.0009203 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="2-lineaarne-regressioon.html#cb454-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usalduspiirid robustsete standardvigade alusel saame kätte coefci() </span></span>
<span id="cb454-2"><a href="2-lineaarne-regressioon.html#cb454-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  funktsiooniga</span></span>
<span id="cb454-3"><a href="2-lineaarne-regressioon.html#cb454-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coefci</span>(mudel6, <span class="at">vcov. =</span> <span class="fu">vcovHC</span>(mudel6))</span></code></pre></div>
<pre><code>##                          2.5 %     97.5 %
## (Intercept)        30.66233656 41.5957223
## literacy            0.85212087  0.8909250
## suguNaine          -2.91369599 12.1071535
## literacy:suguNaine -0.07150916 -0.0183653</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>Lineaarse regressiooni puhul peaks tähelepanelik olema ka <strong>erindite</strong> (<em>outliers</em>)suhtes, st vaatluste suhtes, mis erinevad teistest väga olulisel määral (nagu ka kõrvalolevalt jooniselt näha). Mõnede andmete puhul on erindid paratamatud (näiteks sissetuleku puhul, kus suurem osa inimesi on koondunud keskmise sissetuleku ümber, kuid mõned üksikud teenivad sellest oluliselt enam). Sellisel juhul tasuks kaaluda jällegi tunnuse transformeerimist (sissetuleku puhul näiteks log-skaalale). Kui tegemist on mõne üksiku erindiga, võiks ju selle aluseks oleva vaatluse ka lihtsalt analüüsist välja jätta. Siin tuleks aga olla väga ettevaatlik. Andmete või sellest saadava informatsiooni tahtlik vähendamine (näiteks pidevtunnuste kategoriseerimine) ei ole üldiselt kunagi hea mõte. Seda enam ei ole hea mõte andmete vähendamine eesmärgiga mudelit paremaks teha. Kui aga erindite tekkimine on mingil moel teoreetiliselt seletatav või tulenenud näiteks veast andmekorjel, siis võib seda loomulikult teha.</p></li>
<li><p><strong>Jääkide normaaljaotus</strong>. Regressiooni jäägid peaksid olema normaaljaotusega <span class="math inline">\(e_i \sim N(0, \sigma^2)\)</span>, seega enamus jääke peaks jääma nulli ümber ning mida suuremad jäägid, seda vähem neid olema peaks. See eeldus on eelkõige oluline regressioonikoefitsientide <em>t</em>-testi jaoks.</p></li>
<li><p>Kui kaks sõltumatut tunnust on teineteisega väga tugevalt seotud põhjusteab see nn <strong>kollineaarsust</strong>. See võib tekitada probleeme mudeli hindamisel ning ka tõlgendusel. Lisaks kipuvad standardvead liialt suureks minema, mis tähendab seda, et kaotame oma tulemuste täpsuses ja võime mitte näha seoseid seal, kus need tegelikult olemas on. Seega võiks tähele panna, et korrelatsioon sõltumatute muutujate vahel peaks alati olema väiksem kui korrelatsioon sõltuva ja sõltumatu muutuja vahel.</p></li>
</ol>
</div>
<div id="kuidas-eelduste-täidetust-hinnata" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Kuidas eelduste täidetust hinnata?<a href="2-lineaarne-regressioon.html#kuidas-eelduste-täidetust-hinnata" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Eelduste hindamiseks on loomulikult mitmeid teste, kuid kõige lihtsam on seda mudeli diagnostiliste joonistega. Saaksime need ka ise teha, kuid lihtsam on kasutada käsku <code>plot()</code>, kui sellesse sisestada mudeliobjekti nimi, siis kuvab R järjest erinevad diagnostikaplotid (järgmise ploti nägemiseks peab Return’i vajutama). Teine võimalus on anda <code>plot()</code> käsule numbriline lisaprameeter (nagu ka järgnevalt on tehtud).</p>
<p>Defineerime kõigepealt mudeli:</p>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="2-lineaarne-regressioon.html#cb456-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> sissetulek <span class="sc">~</span> numeracy <span class="sc">+</span> vanus <span class="sc">+</span> sugu <span class="sc">+</span> haridustase, </span>
<span id="cb456-2"><a href="2-lineaarne-regressioon.html#cb456-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> piaac)</span></code></pre></div>
<div id="lineaarne-seos-ja-jääkide-dispersiooni-homogeensus." class="section level3 hasAnchor" number="2.10.1">
<h3><span class="header-section-number">2.10.1</span> Lineaarne seos ja jääkide dispersiooni homogeensus.<a href="2-lineaarne-regressioon.html#lineaarne-seos-ja-jääkide-dispersiooni-homogeensus." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Vaatame kõigepealt jäägid vs hinnatud väärtused joonist. Kontrollime sellega mittelineaarse seose olemasolu ja jääkide dispersiooni homogeensust. Punktid peaksid olema kogu x-telje ulatuses ühtlaselt ümber keskmise 0-joone jaotunud nii, et igas x-telje punktis oleks jääkide keskmine 0 (punane joon ehk jääkide keskminepeaks langema kokku 0-joonega). Ei tohiks näha olla mingit ilmset mustrit. Kui jäägid ei ole ühtlaselt ümber kesjoone, siis on probleemiks lineaarsuse eeldus. Kui jäägid ei ole kogu skaala ulatuses ühtlaselt jaotunud, siis on probleem jääkide dispersiooniga.</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="2-lineaarne-regressioon.html#cb457-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">1</span>)</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Siin ilmselgelt on muster olemas. Mida suurem on hinnatud väärtus, seda suurem on jääkide dispersioon. Samuti on positiivsed jäägid suuremad kui negatiivsed. Võib järeldada, et meie mudelil on probleeme nii lineaarsusega (suuremad positiivsed jäägid), kui ka jääkide dispersiooni homogeensusega (jääkide dispersioon on paremal, suuremate hinnatud väärtuste juures, oluliselt suurem kui vasakul).</p>
<p>Jääkide dispersiooni homogeensust saame ka fomraalsemalt kontrollida Breusch-Pagan testiga. Selle puhul on nullhüpoteesik konstantne varieeruvus (<em>homoscedasticity</em>) ja alternativvseks hüpoteesiks mittekonstantne varieeruvus (<em>heteroscedasticity</em>). Ehk siis me tahaksime näha võimalikult suurt <em>p</em> väärtust, mis tähendaks, et nullhüpoteesi kehtimise tõenäosus on suur (meil ei ole piisavalt tõendeid, et seda ümber lükata)</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="2-lineaarne-regressioon.html#cb458-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Breusch-Pagan test on olemas lmtest paketis.</span></span>
<span id="cb458-2"><a href="2-lineaarne-regressioon.html#cb458-2" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">bptest</span>(mod)</span></code></pre></div>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  mod
## BP = 192.88, df = 5, p-value &lt; 2.2e-16</code></pre>
<p><em>p</em> väärtus on väga väike, seega saame kinnitust oma varasemale järeldusele, et jääkide dispoersioon ei ole homogeenne.</p>
</div>
<div id="jääkide-normaaljaotus" class="section level3 hasAnchor" number="2.10.2">
<h3><span class="header-section-number">2.10.2</span> Jääkide normaaljaotus<a href="2-lineaarne-regressioon.html#jääkide-normaaljaotus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jääkide normaaljaotuse eeldust saame kontrollida Q-Q plot’iga. Kui jäägid on normaalselt jaotunud, siis peaksid punktid enamvähem ühtima diagonaalse joonega. Jällegi tundub, et see eeldus on kaugel täidetust.</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="2-lineaarne-regressioon.html#cb460-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">2</span>)</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-28-1.png" width="672" />
Normaajaotuse kehtivust saame formaalselt kontrollida Shapiro-Wilk testiga, kus nullhüpoteesiks on normaaljaotus. Seega ootame jällegi võimalikult suurt <em>p</em> väärtust, mis kinnitaks meile, et meil ei ole põhjust nullhüpoteesi kummutada.</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="2-lineaarne-regressioon.html#cb461-1" aria-hidden="true" tabindex="-1"></a><span class="co"># resid() funktsiooniga saame mudeliobjektist jäägid välja võtta</span></span>
<span id="cb461-2"><a href="2-lineaarne-regressioon.html#cb461-2" aria-hidden="true" tabindex="-1"></a>jaagid <span class="ot">&lt;-</span> <span class="fu">resid</span>(mod)</span>
<span id="cb461-3"><a href="2-lineaarne-regressioon.html#cb461-3" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(jaagid)</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  jaagid
## W = 0.8749, p-value &lt; 2.2e-16</code></pre>
<p><em>p</em> väärtus on väga väike, mis kinnitab meile, et jäägid ei ole normaalselt jaotunud.</p>
</div>
<div id="jääkide-dispersiooni-homogeensus" class="section level3 hasAnchor" number="2.10.3">
<h3><span class="header-section-number">2.10.3</span> Jääkide dispersiooni homogeensus<a href="2-lineaarne-regressioon.html#jääkide-dispersiooni-homogeensus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jääkide dispersiooni homogeensust saame kontrollida ka <em>scale-location</em> joonisega, kus on jällegi kuvatud jäägid vs hinnatud väärtused, kuid jäägid on siin standardiseeritud ja neist on ruutjuur võetud. Tahaksime näha, et punane joon (standardiseeritud jääkide keskmine) oleks paralleelne x-teljega. Jällegi, siinsel pildil see nii ei ole.</p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="2-lineaarne-regressioon.html#cb463-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">3</span>)</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
<div id="mõjukad-vaatlused" class="section level3 hasAnchor" number="2.10.4">
<h3><span class="header-section-number">2.10.4</span> Mõjukad vaatlused<a href="2-lineaarne-regressioon.html#mõjukad-vaatlused" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Cook’s distance</em> joonisel on kuvatud iga vaatluse mõju suurus regressioonikoefitseintidele. Täpsemalt näitab see kui palju tulemused muutuksid, kui iga vaatlus järgemööda mudelist välja võtta. Mida kõrgem on vaatluse joon, seda mõjukam see on. Vaatlused, mis enam esile kerkivad vääriksid tähelepanu. Need võivad olla erindid, mis võivad tuleneda näiteks andmete sisestamisveast vms. Igal juhul ei ole nad nn tavapärased vaatlused, mille kohta me tahame järeldusi teha.</p>
<p>Märkimisväärseks <em>Cook</em>-i kauguse väärtuseks loetakse tegelikult 0.5 või isegi 1. Meie joonisel on nende numbritega võrreldes vaga tagasihoidlikud kaugused. Ehk siis võime järeldada, et mõjukaid vaatlusi meie mudelis ei ole.</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="2-lineaarne-regressioon.html#cb464-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">4</span>)</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>Ka <em>residuals vs leverage</em> joonis aitab esile tuua mõjukaid vaatlusi. Taolised vaatlused olema paremal all või paremal üleval nurgas ning kaugemal kui punktiirjoon (antud juhul neid ei ole ja seega ei ole ka punktiirjoont näha).</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="2-lineaarne-regressioon.html#cb465-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">5</span>)</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
</div>
</div>
<div id="tunnuste-transformatsioonid" class="section level2 hasAnchor" number="2.11">
<h2><span class="header-section-number">2.11</span> Tunnuste transformatsioonid<a href="2-lineaarne-regressioon.html#tunnuste-transformatsioonid" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Oleme eelnevalt mitmel puhul maininud, et nii andmete tõlgendamisel kui regressiooni eelduste täitmisel võivad abiks olla tunnuste transformatsioonid. Need võivad olla nii lineaarsed (kus seosed iseenesest ei muutu, kuid muutub selle tõlgendus - eeldatavalt lihtsamaks) ja mitte-lineaarsed (millega muudetakse seose kuju).</p>
<div id="lineaarsed-transformatsioonid" class="section level3 hasAnchor" number="2.11.1">
<h3><span class="header-section-number">2.11.1</span> Lineaarsed transformatsioonid<a href="2-lineaarne-regressioon.html#lineaarsed-transformatsioonid" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Nagu mainitud, siis lineaarsed transformatsioonid aitavad eelkõige mudeleid lihtsamini tõlgendada. Koosmõjude peatükis oli meil mudel, mille otsene interpretatsioon oli suhteliselt keerukas:</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="2-lineaarne-regressioon.html#cb466-1" aria-hidden="true" tabindex="-1"></a>mudel8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> numeracy <span class="sc">*</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb466-2"><a href="2-lineaarne-regressioon.html#cb466-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel8)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ numeracy * sugu, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1213.35  -322.79   -99.79   166.87  2802.32 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          28.4609    79.7161   0.357   0.7211    
## numeracy              3.7552     0.2815  13.340   &lt;2e-16 ***
## suguNaine          -157.9875   107.6870  -1.467   0.1424    
## numeracy:suguNaine   -0.7476     0.3840  -1.947   0.0516 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 525.8 on 3980 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.1718, Adjusted R-squared:  0.1712 
## F-statistic: 275.2 on 3 and 3980 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Asi oli selles, et <em>numeracy</em> skoori 0-väärtus ei ole realistlik. Kuid meeste ja naiste sissetulekute erinevus on määratletud referentsgrupi (mehed, kelle <em>numeracy</em> on 0) suhtes.</p>
<div id="tunnuste-standardiseerimine" class="section level4 unnumbered hasAnchor">
<h4>Tunnuste standardiseerimine<a href="2-lineaarne-regressioon.html#tunnuste-standardiseerimine" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Kuid me saame <em>numeracy</em> skaalat, ja seega ka referentspunkti, muuta. Selleks on mitmeid võimalusi, kuid üheks tavapärasemaks on tunnuste <strong>standardiseerimine</strong>. Standardiseeritud tunnuse väärtusi nimetatakse ka z-skoorideks. Standardiseeritud tunnuse keskmine on 0 ja ühikuks on tunnuse standardhälve. Standardiseerime <em>numeracy</em> tunnuse:</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="2-lineaarne-regressioon.html#cb468-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lahutame tunnusest tunnuse keskmise ja jagame läbi tunnuse standardhälbega</span></span>
<span id="cb468-2"><a href="2-lineaarne-regressioon.html#cb468-2" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb468-3"><a href="2-lineaarne-regressioon.html#cb468-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z_num =</span> (numeracy <span class="sc">-</span> <span class="fu">mean</span>(numeracy, <span class="at">na.rm =</span> T))<span class="sc">/</span><span class="fu">sd</span>(numeracy, <span class="at">na.rm =</span> T))</span>
<span id="cb468-4"><a href="2-lineaarne-regressioon.html#cb468-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb468-5"><a href="2-lineaarne-regressioon.html#cb468-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Lihtsam oleks tegelikult kasutada scale(funktsiooni). Selle väljund</span></span>
<span id="cb468-6"><a href="2-lineaarne-regressioon.html#cb468-6" aria-hidden="true" tabindex="-1"></a><span class="co"># on maatriks, sellepärast peame ta ka numbriliseks tegema</span></span>
<span id="cb468-7"><a href="2-lineaarne-regressioon.html#cb468-7" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb468-8"><a href="2-lineaarne-regressioon.html#cb468-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">z_num =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(numeracy)))</span></code></pre></div>
<p>Jooksutame nüüd standardiseeritud tunnusega uuesti mudelit:</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="2-lineaarne-regressioon.html#cb469-1" aria-hidden="true" tabindex="-1"></a>mudel_stnd <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> z_num <span class="sc">*</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb469-2"><a href="2-lineaarne-regressioon.html#cb469-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel_stnd)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ z_num * sugu, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1213.35  -322.79   -99.79   166.87  2802.32 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      1050.12      13.03  80.587   &lt;2e-16 ***
## z_num             169.69      12.72  13.340   &lt;2e-16 ***
## suguNaine        -361.40      17.02 -21.236   &lt;2e-16 ***
## z_num:suguNaine   -33.78      17.35  -1.947   0.0516 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 525.8 on 3980 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.1718, Adjusted R-squared:  0.1712 
## F-statistic: 275.2 on 3 and 3980 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Enne oli jutuks, et lineaarsete transformatsioonide puhul mudel ise ei muutu, aga nüüd näeme, et standardiseeritud tunnusega mudelis on nii erinevad koefitsiendid, t-väärtused kui ka p-väärtused. Ja kui enne soo mõju ei olnud oluline, siis nüüd on.</p>
<p>Kuid kui tulemeid lähemalt vaadata, siis näeme, et nii R2 väärtus, RSE väärtus kui F-statistik on mudelite puhul samad. Ehk siis tegelikult on tegemist ikkagi samade mudelitega. <em>suguNaine</em> koefitsient on erinev, kuna esimeses mudelis oli see soo erinevus <em>numeracy</em> 0 väärtuse korral, nüüd aga standardiseeritud <em>numeracy</em> 0 väärtuse korral, ehk siis tegelikult <em>numeracy</em> keskväärtuse korral. Kuna mudelis on defineeritud ka soo ja <em>numeracy</em> koosmõju, siis soo mõju on erinevate <em>numeracy</em> väärtuste korral erinev.</p>
<p>Tulemit saame tõlgendada järgnevalt:</p>
<ul>
<li>Vabaliige on meeste keskmine sissetulek populatsiooni keskmise <em>numeracy</em> skoori korral<br />
</li>
<li><em>z_num</em> on keskmise sissetuleku muutus kui <em>numeracy</em> skoor muutub ühe standardhälbe võrra<br />
</li>
<li><em>suguNaine</em> on popultasiooni keskmise <em>numeracy</em> skooriga naiste erinevus samaväärsetest meestest<br />
</li>
<li><em>z_num:suguNaine</em> on naiste <em>z_num</em> koefitsiendi erinevus meeste <em>z_num</em> koefitsiendist, ehk siis naiste puhul on <em>numeracy</em> mõju sissetulekule laugem</li>
</ul>
<p>Standardiseerimise puhul on positiivne, et saame võimalike erinevate skaaladega tunnused sarnasele standardhälbe skaalale panna. Kuid skaala ise muutub abstraktsemaks. Standardhälve ei ole ülemäära lihtsalt hoomatav suurus.</p>
</div>
<div id="tunnuste-tsentreerimine" class="section level4 unnumbered hasAnchor">
<h4>Tunnuste tsentreerimine<a href="2-lineaarne-regressioon.html#tunnuste-tsentreerimine" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Kui tahame skaalat säilitada, kui ikkagi mudeli interpreteeritavust parandada, siis on abiks tunnuste <strong>tsentreerimine</strong>, mis tähendab, et liigutame tunnuse keskpunkti nulli, kuid jätame skaala samaks:</p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="2-lineaarne-regressioon.html#cb471-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Lahutame tunnusest tunnuse keskmise </span></span>
<span id="cb471-2"><a href="2-lineaarne-regressioon.html#cb471-2" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb471-3"><a href="2-lineaarne-regressioon.html#cb471-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">t_num =</span> (numeracy <span class="sc">-</span> <span class="fu">mean</span>(numeracy, <span class="at">na.rm =</span> T)))</span>
<span id="cb471-4"><a href="2-lineaarne-regressioon.html#cb471-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb471-5"><a href="2-lineaarne-regressioon.html#cb471-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Lihtsam oleks tegelikult kasutada scale(funktsiooni). Selle väljund</span></span>
<span id="cb471-6"><a href="2-lineaarne-regressioon.html#cb471-6" aria-hidden="true" tabindex="-1"></a><span class="co"># on maatrix, sellepärast peame ta ka numbriliseks tegema</span></span>
<span id="cb471-7"><a href="2-lineaarne-regressioon.html#cb471-7" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb471-8"><a href="2-lineaarne-regressioon.html#cb471-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">t_num =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(numeracy, <span class="at">scale =</span> F)))</span></code></pre></div>
<div class="sourceCode" id="cb472"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb472-1"><a href="2-lineaarne-regressioon.html#cb472-1" aria-hidden="true" tabindex="-1"></a>mudel_stnd <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> t_num <span class="sc">*</span> sugu, <span class="at">data =</span> piaac)</span>
<span id="cb472-2"><a href="2-lineaarne-regressioon.html#cb472-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mudel_stnd)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ t_num * sugu, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1213.35  -322.79   -99.79   166.87  2802.32 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     1050.1190    13.0309  80.587   &lt;2e-16 ***
## t_num              3.7552     0.2815  13.340   &lt;2e-16 ***
## suguNaine       -361.3960    17.0182 -21.236   &lt;2e-16 ***
## t_num:suguNaine   -0.7476     0.3840  -1.947   0.0516 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 525.8 on 3980 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.1718, Adjusted R-squared:  0.1712 
## F-statistic: 275.2 on 3 and 3980 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Tõlgendus on täpselt sama mis standardiseeritud tunnuse puhul, välja arvatud see, et <em>z_num</em> puhul ei räägi me enam standardhälbest, vaid originaalsest <em>numeracy</em> skoorist:</p>
<ul>
<li>Vabaliige on meeste keskmine sissetulek populatsiooni keskmise <em>numeracy</em> skoori korral<br />
</li>
<li><em>t_num</em> on keskmise sissetuleku muutus kui <em>numeracy</em> skoor muutub ühe ühiku võrra<br />
</li>
<li><em>suguNaine</em> on popultasiooni keskmise <em>numeracy</em> skooriga naiste erinevus samaväärsetest meestest<br />
</li>
<li><em>t_num:suguNaine</em> on naiste <em>t_num</em> koefitsiendi erinevus meeste <em>t_num</em> koefitsiendist, ehk siis naiste puhul on <em>numeracy</em> mõju sissetulekule laugem</li>
</ul>
<p>Ja me ei pea tunnuseid tsentreerima nende keskväärtustest lähtuvalt. Kui meil on mõne tunnuse kohta mingi konkreetne sisuline väärtus, mida tahame referentsina kasutada, siis saame seda kasutada. Näiteks meil on mudelis vanuse tunnus ja valimis ainult täisealised - seega vanus 0 on jällegi täiesti sisutu. Kui nüüd tahame referentsina kasutada näiteks 30-aastaseid, siis saame vanuse tsentreerida lähtuvalt sellest punktist:</p>
<div class="sourceCode" id="cb474"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb474-1"><a href="2-lineaarne-regressioon.html#cb474-1" aria-hidden="true" tabindex="-1"></a>piaac <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb474-2"><a href="2-lineaarne-regressioon.html#cb474-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">vanus_30 =</span> vanus <span class="sc">-</span> <span class="dv">30</span>)</span>
<span id="cb474-3"><a href="2-lineaarne-regressioon.html#cb474-3" aria-hidden="true" tabindex="-1"></a>mudel_stnd <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> vanus_30, <span class="at">data =</span> piaac)</span></code></pre></div>
</div>
</div>
<div id="mitte-lineaarsed-transformatsioonid" class="section level3 hasAnchor" number="2.11.2">
<h3><span class="header-section-number">2.11.2</span> Mitte-lineaarsed transformatsioonid<a href="2-lineaarne-regressioon.html#mitte-lineaarsed-transformatsioonid" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mitte-lineaarsed transformatsioonid tulevad mängu eelkõige siis, kui meil on probleeme mudeli eelduste täidetusega. Aga mitte ainult, teatud juhtudel võivad nad ka lihtsustada mudeli tõlgendust. Erinevaid transformatsioone on palju ja erisuguseid, kuid ülekaalukalt kaks kõige levinumat on log-transformatsioon ja polünoomide kaasamine.</p>
<div id="log-transformatsioonid" class="section level4 unnumbered hasAnchor">
<h4>Log-transformatsioonid<a href="2-lineaarne-regressioon.html#log-transformatsioonid" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Log-transformatsiooni on võimalik tunnust, mille jaotus on paremale “välja veninud” (sellist jaotust nimetataksegi log-normaalseks jaotuseks) normaaljaotusele sarnasemaks teha. Näiteks sissetulek on väga tihti sellise väljaveninud jaotusega, kuna võrreldes keskmise palga saajatega on kõrge palga saajaid rohkem kui madala palga saajaid (joonis <a href="2-lineaarne-regressioon.html#fig:sissetulek-jaotus">2.5</a>). Sellist jaotust iseloomustab asjaolu, et selle keskmine ja mediaan ei ole samad (normaaljaotuse puhul peaksid need ühtima), vaid keskmine on mediaanist paremal. See on ka põhjus miks keskmise palga asmel räägitakse tihti mediaanpalgast. Mediaan jagab inimesed jaotuse pooleks (pooled saavad vähem ja pooled rohkem palka kui mediaan). Keskmisest kõrgemat palka saab aga vähem inimesi, kui keskmisest madalamat palka.</p>
<div class="figure"><span style="display:block;" id="fig:sissetulek-jaotus"></span>
<p class="caption">
Joonis 2.5: Sissetuleku jaotus
</p>
<img src="01-regressioon_files/figure-html/sissetulek-jaotus-1.png" alt="Sissetuleku jaotus" width="672" />
</div>
<p>Võttes sellisest tunnusest logaritmi, muudame jaotuse kuju rohkem normaaljaotuse sarnaseks.</p>
<div id="logaritm" class="section level5 unnumbered hasAnchor">
<h5>Logaritm<a href="2-lineaarne-regressioon.html#logaritm" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Meeldetuletuseks, et mis see logaritm üldse on:</p>
<p><span class="math display">\[\log_a{b} = x \, \iff \, b = a^x\]</span></p>
<p>ehk siis <span class="math inline">\(x\)</span> on arvu <span class="math inline">\(b\)</span> logaritm alusel <span class="math inline">\(a\)</span>, kui <span class="math inline">\(b = a^x\)</span>. Logaritmi alusena kasutame üldjuhul <span class="math inline">\(e\)</span> (ehk Euleri arv väärtusega <em>ca</em> 2,71828…). Logaritmi, mille aluse on <span class="math inline">\(e\)</span> nimetatakse ka naturaallogaritmiks. Ris on logaritmi funktsiooniks <code>log()</code> ja vaikimisi annabki see naturaallogaritmi.</p>
<p>Tabelis <a href="2-lineaarne-regressioon.html#tab:tab-log">2.1</a> on näha erinevate väärtuste logaritmid. 0-i logaritm ei ole defineeritud, st 0-st logaritmi võtta ei saa. Seda tuleks siis ka tunnuste transformeerimisel meeles pidada - saame logaritmida ainult positiivsete väärtustega tunnuseid. 1-e logaritm on 0. Näeme, et logaritmimine vähendab suuri väärtusi ja suurendab väikeseid väärtusi.</p>
<table class="huxtable" style="border-collapse: collapse; border: 0px; margin-bottom: 2em; margin-top: 2em; ; margin-left: 0%; margin-right: auto;  " id="tab:tab-log">
<caption style="caption-side: top; text-align: left;"><span id="tab:tab-log">Tabel 2.1: </span> Logaritmid</caption><col style="width: 60%"><col style="width: 60%"><tr>
<th style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: bold;">b</th><th style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: bold;">log(b)</th></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">     0</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">-Inf&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">     0.00001</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">-11.5&nbsp;&nbsp;</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">     0.5</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">-0.693</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">     1</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">0&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">     2</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">0.693</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">    10</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">2.3&nbsp;&nbsp;</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">   100</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">4.61&nbsp;</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">  1000</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">6.91&nbsp;</td></tr>
<tr>
<td style="vertical-align: top; text-align: left; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 1pt 1pt 0pt; font-weight: normal;">100000</td><td style="vertical-align: top; text-align: right; white-space: normal; border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;    padding: 1pt 0pt 1pt 1pt; font-weight: normal;">11.5&nbsp;&nbsp;</td></tr>
</table>

<p>Vaatame kuidas näeb välja eelmisel joonisel kuvatud sissetuleku jaotus logaritmitud kujul:</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-39"></span>
<p class="caption">
Joonis 2.6: Sissetuleku logaritmitud skaala võrdluses originaalskaalaga
</p>
<img src="01-regressioon_files/figure-html/unnamed-chunk-39-1.png" alt="Sissetuleku logaritmitud skaala võrdluses originaalskaalaga" width="672" />
</div>
<p>Tundub märksa sarnasem normaaljaotusele.</p>
<p>Regressioonimudeli kontekstis tahame sõltuvat tunnust näha normaaljaotusena eelkõige sellepärast, et väljaveninud sabadega jaotused (või muud jaotused, mis ei vasta normaaljaotusele) kipuvad mõjutama jääkide jaotust ning nende seosed teiste tunnustega kipuvad olema mittelineaarsed.</p>
<p>Kui vaadata sissetuleku regressioonseost <em>numeracy</em>-ga (joonis <a href="2-lineaarne-regressioon.html#fig:log-reg">2.7</a>), siis on näha, et originaalskaala puhul on positiivsed (regressioonijoonest kõrgemale jäävaid) jäägid oluliselt suuremad kui negatiivsed, log-tranformeeritud skaala puhul on jäägid aga ühtlaselt ümber regressioonijoone jaotunud.</p>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="2-lineaarne-regressioon.html#cb475-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb475-2"><a href="2-lineaarne-regressioon.html#cb475-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>()<span class="sc">+</span></span>
<span id="cb475-3"><a href="2-lineaarne-regressioon.html#cb475-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> numeracy, <span class="at">y =</span> sissetulek)<span class="sc">+</span></span>
<span id="cb475-4"><a href="2-lineaarne-regressioon.html#cb475-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>)<span class="sc">+</span></span>
<span id="cb475-5"><a href="2-lineaarne-regressioon.html#cb475-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&#39;lm&#39;</span>, <span class="at">se =</span> F, <span class="at">color =</span> <span class="st">&quot;#972D15&quot;</span>)<span class="sc">+</span></span>
<span id="cb475-6"><a href="2-lineaarne-regressioon.html#cb475-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb475-7"><a href="2-lineaarne-regressioon.html#cb475-7" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> piaac <span class="sc">%&gt;%</span> </span>
<span id="cb475-8"><a href="2-lineaarne-regressioon.html#cb475-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>()<span class="sc">+</span></span>
<span id="cb475-9"><a href="2-lineaarne-regressioon.html#cb475-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> numeracy, <span class="at">y =</span> <span class="fu">log</span>(sissetulek))<span class="sc">+</span></span>
<span id="cb475-10"><a href="2-lineaarne-regressioon.html#cb475-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.2</span>)<span class="sc">+</span></span>
<span id="cb475-11"><a href="2-lineaarne-regressioon.html#cb475-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&#39;lm&#39;</span>, <span class="at">se =</span> F, <span class="at">color =</span> <span class="st">&quot;#972D15&quot;</span>)<span class="sc">+</span></span>
<span id="cb475-12"><a href="2-lineaarne-regressioon.html#cb475-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb475-13"><a href="2-lineaarne-regressioon.html#cb475-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb475-14"><a href="2-lineaarne-regressioon.html#cb475-14" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">+</span>p2</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:log-reg"></span>
<p class="caption">
Joonis 2.7: Regressioonijooned ja jääkide jaotus originaalskaala ja log-transformeeritud skaala puhul.
</p>
<img src="01-regressioon_files/figure-html/log-reg-1.png" alt="Regressioonijooned ja jääkide jaotus originaalskaala ja log-transformeeritud skaala puhul." width="672" />
</div>
</div>
<div id="logaritmitud-sõltuv-muutuja" class="section level5 unnumbered hasAnchor">
<h5>Logaritmitud sõltuv muutuja<a href="2-lineaarne-regressioon.html#logaritmitud-sõltuv-muutuja" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Kui kasutada regressioonimudelis logaritmitud sõltuvat tunnust, siis peab meeles pidama, et <strong>tunnuse log-transformeerimine muudab koefitsientide tõlgendust</strong>. Me ei hinda enam sissetulekut vaid log-sissetulekut:</p>
<p><span class="math display">\[\log(Y_i) = \beta_0 + \beta_1 x_i + \epsilon_i\]</span>
ja seega <span class="math inline">\(\beta_1\)</span> tõlgendus on, et kui <span class="math inline">\(x\)</span> muutub ühe ühiku võrra, siis <span class="math inline">\(log(Y)\)</span> muutub <span class="math inline">\(\beta_1\)</span> võrra. Log-sissetulekut on aga suhteliselt keeruline tõlgendada, seetõttu viiakse mudel üldjuhul tagasi originaalsele <span class="math inline">\(y\)</span> skaalale, võttes võrrandi mõlemast poolest eksponendi (eksponent on logaritmi pöördtehe: <span class="math inline">\(\exp(\log(10)) = 10\)</span>):</p>
<p><span class="math display">\[e^{(\log(Y_i))} = e^{(\beta_0 + \beta_1 x_i + \epsilon_i)}\Rightarrow Y_i = e^{(\beta_0)} \cdot e^{(\beta_1 x_i)} \cdot e^{(\epsilon_i)}\]</span>
Nüüd on <span class="math inline">\(Y\)</span> küll originaalskaalal, kuid võrrand ise on muutunud multiplikatiivseks (sest <span class="math inline">\(a^m \times a^n = a^{m+n}\)</span>). See tähendab, et kui <strong>kui <span class="math inline">\(x\)</span> muutub ühe ühiku võrra, siis <span class="math inline">\(Y\)</span> muutub <span class="math inline">\(\exp(\beta_1)\)</span> korda</strong>.</p>
<p>Defineerime log-transformeeritud sissetulekuga mudeli ja interpreteerime seda:</p>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="2-lineaarne-regressioon.html#cb476-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Me ei ilmtingimata andmestikku uut log-tunnust tegema. Saame ka lm()</span></span>
<span id="cb476-2"><a href="2-lineaarne-regressioon.html#cb476-2" aria-hidden="true" tabindex="-1"></a><span class="co"># funktsiooni sees log() funktsiooni  kasutada.</span></span>
<span id="cb476-3"><a href="2-lineaarne-regressioon.html#cb476-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(sissetulek) <span class="sc">~</span> numeracy, <span class="at">data =</span> piaac)</span>
<span id="cb476-4"><a href="2-lineaarne-regressioon.html#cb476-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(sissetulek) ~ numeracy, data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.16429 -0.37750  0.00272  0.36621  1.84684 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 5.412322   0.060708   89.15   &lt;2e-16 ***
## numeracy    0.004145   0.000217   19.10   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5971 on 3982 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.08394,    Adjusted R-squared:  0.08371 
## F-statistic: 364.9 on 1 and 3982 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>Vabaliikme eksponent on sissetuleku geomeetriline keskmise (pane tähele, et mitte aritmeetilise keskmise) juhul kui <em>numeracy</em> skoor on 0, Seega <span class="math inline">\(\exp(5.4123218) = 224.151415\)</span>.<br />
</li>
<li><em>numeracy</em> eksponent näitab mitu korda keskmine geomeetriline sissetulek kasvab, kui <em>numeracy</em> skoor muutub ühe ühiku võrra. <span class="math inline">\(\exp(0.0041452) = 1.0041539\)</span>, mis tähendab, et sissetulek kasvab 1.004 korda, ehk 0.4%. 10-punktine <em>numeracy</em> kasv tähendaks aga <span class="math inline">\(\exp(0.0041\times 10) =1.042\)</span> kordset kasvu ehk 4.19%-st kasvu.</li>
</ul>
<p>Kui <span class="math inline">\(-0.1 &lt; \beta &lt; 0.1\)</span>, siis on päris täpne lähend <span class="math inline">\(y\)</span> protsentuaalsele muutusele <span class="math inline">\(100 \times \beta\)</span>, ehk antud juhul oleks <em>numeracy</em> 10-punktine kasv võrdne <span class="math inline">\(100 \times 0.0041 \times 10 = 4.1%\)</span> sissetuleku kasvuga.</p>
</div>
<div id="logaritmitud-sõltumatu-muutuja" class="section level5 unnumbered hasAnchor">
<h5>Logaritmitud sõltumatu muutuja<a href="2-lineaarne-regressioon.html#logaritmitud-sõltumatu-muutuja" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Kui me logaritmime sõltumatut muutuja <span class="math inline">\(x\)</span>-i, siis <strong>1% muutus <span class="math inline">\(x\)</span>-is tähendab <span class="math inline">\(\beta_1 \times \log(1.01)\)</span> muutust <span class="math inline">\(y\)</span>-is</strong>.</p>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="2-lineaarne-regressioon.html#cb478-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> <span class="fu">log</span>(numeracy), <span class="at">data =</span> piaac)</span>
<span id="cb478-2"><a href="2-lineaarne-regressioon.html#cb478-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ log(numeracy), data = piaac)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -946.6 -352.4 -130.4  183.8 2905.3 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -4106.25     294.42  -13.95   &lt;2e-16 ***
## log(numeracy)   884.73      52.47   16.86   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 558.1 on 3982 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.06663,    Adjusted R-squared:  0.0664 
## F-statistic: 284.3 on 1 and 3982 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>Vabaliige on keskmine sissetulek, kui log(<em>numeracy</em>) on 0 ehk kui <em>numeracy</em> on 1 (sest <span class="math inline">\(log(1) = 0\)</span>)</li>
<li>Kui <em>numeracy</em> muutub 1% võrra, siis keskmine sissetulek kasvab <span class="math inline">\(884.7341221 \times log(1.01) = 8.803\)</span> euro võrra.</li>
</ul>
<p>Küllaltki täpse lähendi <span class="math inline">\(y\)</span> kasvule saame kui jagame koefitsiendi lihtsalt 100-ga läbi: <span class="math inline">\(\frac{884.7341221}{100} = 8.847\)</span>.</p>
</div>
<div id="logaritmitud-sõltuv-ja-sõltumatu-muutuja" class="section level5 unnumbered hasAnchor">
<h5>Logaritmitud sõltuv ja sõltumatu muutuja<a href="2-lineaarne-regressioon.html#logaritmitud-sõltuv-ja-sõltumatu-muutuja" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Kui me logaritmime nii sõltuva kui sõltumatu muutuja, siis <strong>1% <span class="math inline">\(x\)</span> muutus tähendab t <span class="math inline">\((1 + 0.01)^\beta\)</span> kordset muutust <span class="math inline">\(Y\)</span>-s</strong> (või siis <span class="math inline">\(\exp(\log(1 + 0.01) \times\beta)\)</span>). Kui <span class="math inline">\(x\)</span> muutub näiteks 10% võrra, siis on <span class="math inline">\(y\)</span> muutub <span class="math inline">\((1+0.1)^\beta\)</span> korda jne. Saame seda näitajat käsitleda protsentuaalse muutusena <span class="math inline">\(((1+0.1)^\beta-1)\times100\)</span>. Taolist näitajat nimetatakse majandusteadustes ka elastsuseks, mis näitab kui tundlik mingi näitaja on teise näitaja muutmise suhtes.</p>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="2-lineaarne-regressioon.html#cb480-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(sissetulek) <span class="sc">~</span> <span class="fu">log</span>(numeracy), <span class="at">data =</span> piaac)</span>
<span id="cb480-2"><a href="2-lineaarne-regressioon.html#cb480-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(sissetulek) ~ log(numeracy), data = piaac)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.13086 -0.37925  0.00297  0.37042  2.14653 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.79591    0.31621   2.517   0.0119 *  
## log(numeracy)  1.02742    0.05636  18.230   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.5994 on 3982 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.07703,    Adjusted R-squared:  0.0768 
## F-statistic: 332.3 on 1 and 3982 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>Kui <em>numeracy</em> muutub 1% võrra, siis keskmine sissetulek muutub <span class="math inline">\((1.01)^{1.0274152} = 1.0102756\%\)</span> korda ehk <span class="math inline">\((1.0102756 - 1) * 100 = 1.0275556\%\)</span> võrra.</li>
</ul>
<p>Kui <span class="math inline">\(\beta\)</span> ei ole väga suur (<span class="math inline">\(-10 &lt; \beta &lt; 10\)</span>), siis jällegi küllaltki heaks lähendiks <span class="math inline">\(y\)</span> muutuse hindamisel on tegelikult lihtsalt <span class="math inline">\(\beta\)</span>, seega 1% muutus <span class="math inline">\(x\)</span>-is tähendab <span class="math inline">\(\beta\%\)</span> muutust <span class="math inline">\(y\)</span>-is.</p>
</div>
</div>
<div id="polünoomid" class="section level4 unnumbered hasAnchor">
<h4>Polünoomid<a href="2-lineaarne-regressioon.html#polünoomid" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Teine väga levinud tunnuse transformeerimise viis on polünoomide mudelisse lisamine. Nende abil on võimalik modelleerida vägagi keerukaid seoseid, millel esmapilgul lineaarsusega mingit seost ei ole.</p>
<p>Polünoomid on funktsioonid, mis koosnevad konstantsete kordajate ja astendatud muutujate summadest.</p>
<p><span class="math display">\[a_0 + a_1x^1 + a_2x^2 + a_3x^3 + a_px^p\]</span>
Graafiliselt näevad polünoomid välja sellised:</p>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p>Polünoomidega regressioonimudeliga saame taolisi ja väga paljusid muid kurve hinnata. Polünoomse regressiooni mudel ise näeb välja järgmine:</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \cdots + \beta_{p-1}x_i^{p-1} + \epsilon_i\]</span></p>
<p>Piaaci andmestikus on vanuse tunnus. Vaatame kuidas vanuse ja sissetuleku seos välja näeb:</p>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="2-lineaarne-regressioon.html#cb482-1" aria-hidden="true" tabindex="-1"></a>piaac <span class="sc">%&gt;%</span> </span>
<span id="cb482-2"><a href="2-lineaarne-regressioon.html#cb482-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> vanus, <span class="at">y =</span> sissetulek))<span class="sc">+</span></span>
<span id="cb482-3"><a href="2-lineaarne-regressioon.html#cb482-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.1</span>)<span class="sc">+</span></span>
<span id="cb482-4"><a href="2-lineaarne-regressioon.html#cb482-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> F, <span class="at">color =</span> <span class="st">&#39;#972D15&#39;</span>)<span class="sc">+</span></span>
<span id="cb482-5"><a href="2-lineaarne-regressioon.html#cb482-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>Tundub päris loogiline. Nooremate inimeste hulgas vanuse kasvades sissetulekud kasvavad, saavutavad 30-35-aastaste hulgas haripunkti ning hakkavad siis langema. Kuid tegemist ei ole mingil juhul lineaarse seosega ning originaalkujul me seda lineaarsesse mudelisse panna ei tohiks.</p>
<p>Üks variant oleks vanus kategoriseerida ning kategoriaalse tunnusena mudelisse kaasata. Sellisel juhul kaotaksime osa infot. Et infokadu vähendada, peaksime tegema suhteliselt palju vanusegruppe. Kuid sellega läheks nende tõlgendamine keerulisemaks.</p>
<p>Teine variant on kasutada polünoome. Sellisel puhul peame otsustama, mitmenda astme polünoomi meil vaja on. Mida kõrgem aste, seda täpsemalt saame seost modelleerida, kuid seda keerulisemaks hilisem tõlgendus läheb. Samuti suureneb oht mudelit <em>overfittida</em>. Rusikareegel on, et mida vähem astmeid, seda parem. Üldiselt tavapärases mudelis üle kolmanda astme ei soovitaks kasutada.</p>
<p>Polünoomidega regressiooni mudeliga tehtavad prognoosid kehtivad üldjuhul ainult mudeli aluseks olevate andmete skaala ulatuses. Näiteks kui kasutame vanuse polünoome ja andmestikus on 20-60 aastased, siis ei tohiks mudeli alusel 80-aastaste inimeste hinnanguid. Väljaspool piiirkonda mille alusel mudel on hinnatud võivad <span class="math inline">\(y\)</span> väärtused väga ebarealistlikuks minna (või no tegelikult lähevad peaaegu kindlasti).</p>
<p>Defineerime esmalt teise astme polünoomiga mudeli. Selleks peame lisaks algsele <em>vanus</em> tunnusele lisama mudelile <em>vanus^2</em> tunnuse (lisades kõrgema astme koefitsienfi, peavad kõik madalama astme koefitsiendid mudelis olema, st kui lisame <em>vanus^2</em>, siis <em>vanus</em> peab ka mudelis olema, kui lisame <em>vanus^3</em>, siis peavad <em>vanus</em> ja <em>vanus^2</em> mudelis olema). Saaksime need enne andmestikus valmis arvutada, kuid lihtsam on need <code>lm()</code> funktsiooni sees defineerida:</p>
<div class="sourceCode" id="cb483"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb483-1"><a href="2-lineaarne-regressioon.html#cb483-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Et võrrandis tehteid teha (antud juhul astendamistehet), </span></span>
<span id="cb483-2"><a href="2-lineaarne-regressioon.html#cb483-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tuleb kasutada I() notatsiooni</span></span>
<span id="cb483-3"><a href="2-lineaarne-regressioon.html#cb483-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span> vanus <span class="sc">+</span> <span class="fu">I</span>(vanus<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> piaac)</span></code></pre></div>
<p>Teine viis polünoomide defineerimiseks on kasutada <code>poly()</code> funktsiooni, mille sisendina peame lisaks tunnusenimele määrama soovitava polünoomi astme. Vaikimisi arvutab <code>poly()</code> ortogonaalsed polünoomid (nende puhul on välditud <span class="math inline">\(x\)</span>, <span class="math inline">\(x^2\)</span>, <span class="math inline">\(x^3\)</span> jne korrelatsioone, andes nii stabiilsema tulemi). Kui tahta <code>poly()</code> funktsiooniga tavapäraseid, käsitsi arvutatavatega analoogseid polünoome, siis tuleb kasutada argumenti <code>raw = T</code>.</p>
<p>Kui tahame hiljem koefitsiente tõlgendada, siis peaksime kasutama tavalisi (<code>raw = T</code>) polünoome, kui tahame mudelit kasutada prognoosimiseks (<code>predict()</code>), siis võiksime eelistada ortogonaalseid polünoome.</p>
<p>Defineerime teise astme polünoomiga mudeli:</p>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="2-lineaarne-regressioon.html#cb484-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span>  <span class="fu">poly</span>(vanus, <span class="at">degree =</span> <span class="dv">2</span>), <span class="at">data =</span> piaac)</span>
<span id="cb484-2"><a href="2-lineaarne-regressioon.html#cb484-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = sissetulek ~ poly(vanus, degree = 2), data = piaac)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -861.6 -368.8 -149.4  186.7 2991.2 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                 822.988      9.494  86.688  &lt; 2e-16 ***
## poly(vanus, degree = 2)1  -4549.436    913.238  -4.982 6.57e-07 ***
## poly(vanus, degree = 2)2 -10723.116    976.876 -10.977  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 566.1 on 3981 degrees of freedom
##   (3648 observations deleted due to missingness)
## Multiple R-squared:  0.03989,    Adjusted R-squared:  0.03941 
## F-statistic: 82.71 on 2 and 3981 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Teise tasandi polünoom on kurvi kujuga, seega seda on hea tahtmise korral võimalik ka koefitsientide abil kirjeldada. Näiteks kui <span class="math inline">\(x^2\)</span> on negatiivne, siis on kurv ülespoole kumer, kui positiivne, siis allapoole kumer. Kuid üldjuhul ei ole mõtet nii koefitsiente tõlgendama hakata. Kuna seos on mittelineaarne, st eri <span class="math inline">\(x\)</span>-i väärtuste korral on see erinev, siis mingit ühest kirjeldust sellele nii ehk naa anda ei saa. Lihtsam on seost graafiliselt vaadata:</p>
<div class="sourceCode" id="cb486"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb486-1"><a href="2-lineaarne-regressioon.html#cb486-1" aria-hidden="true" tabindex="-1"></a>piaac <span class="sc">%&gt;%</span> </span>
<span id="cb486-2"><a href="2-lineaarne-regressioon.html#cb486-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="sc">!</span><span class="fu">is.na</span>(sissetulek), <span class="sc">!</span><span class="fu">is.na</span>(vanus)) <span class="sc">%&gt;%</span> </span>
<span id="cb486-3"><a href="2-lineaarne-regressioon.html#cb486-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">hinnang =</span> <span class="fu">fitted</span>(mod)) <span class="sc">%&gt;%</span> </span>
<span id="cb486-4"><a href="2-lineaarne-regressioon.html#cb486-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>()<span class="sc">+</span></span>
<span id="cb486-5"><a href="2-lineaarne-regressioon.html#cb486-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> vanus, <span class="at">y =</span> hinnang)<span class="sc">+</span></span>
<span id="cb486-6"><a href="2-lineaarne-regressioon.html#cb486-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">&quot;#972D15&quot;</span>)<span class="sc">+</span></span>
<span id="cb486-7"><a href="2-lineaarne-regressioon.html#cb486-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="01-regressioon_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<p>Teeme ka kolmanda astme polünoomidega mudeli:</p>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="2-lineaarne-regressioon.html#cb487-1" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sissetulek <span class="sc">~</span>  <span class="fu">poly</span>(vanus, <span class="at">degree =</span> <span class="dv">3</span>), <span class="at">data =</span> piaac)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-49"></span>
<p class="caption">
Joonis 2.8: Esimese astme polünoom (lineaarne mudel), teise astme polpnoom ja kolmanda astme polünoom võrreldes mittelineaarse GAM hinnanguga
</p>
<img src="01-regressioon_files/figure-html/unnamed-chunk-49-1.png" alt="Esimese astme polünoom (lineaarne mudel), teise astme polpnoom ja kolmanda astme polünoom võrreldes mittelineaarse GAM hinnanguga" width="672" />
</div>

</div>
</div>
</div>
</div>



<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Inglisekeelses terminoloogias kasutatakse sõltuva tunnuse puhul peale <em>dependent variable</em> ka nimetusi <em>response</em> või <em>outcome variable</em> ja sõltumatu tunnuse puhul peale <em>independent variable</em> ka <em>predictor</em> või <em>explanatory variable</em>. Prediktor on ka eesti keeles kasutusel.<a href="2-lineaarne-regressioon.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><em>Defaultis</em> annab <code>geom_smooth</code> meile mittelineaarse regressioonijoone (vastavalt sellele palju vaatlusi on, kas <em>gam</em> või <em>loess</em>), mis üritab tunnustevahelist suhet andmete kõikides punktides võimalikult täpselt kirjeldada.<a href="2-lineaarne-regressioon.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Hiljem, kui meil on mitu sõltumatut tunnust, eristame tunnused plussiga: <code>sõltuv_tunnus ~ sõltumatu_tunnus_1 + sõltumatu_tunnus_2 + ...</code><a href="2-lineaarne-regressioon.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Tegelikult ei ole selline mudel korrektne. Sissetuleku jaotus ei vasta hästi regressiooni nõuetele. Miks ei vasta ja kuidas see vastama panna, sellest natuke hiljem. Kuid hetkel kasutame seda puhtalt didaktilistest kaalutustest lähtuvalt.<a href="2-lineaarne-regressioon.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Mida saab väljendada kui <span class="math inline">\(\epsilon_i=y_i-\hat{y}_i\)</span><a href="2-lineaarne-regressioon.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p><span class="math inline">\(RSS= = e_1^2 + e_2^2 + ... + e_n = \sum_{i=1}^{n}(y_i-\hat{y}_i)^2\)</span><a href="2-lineaarne-regressioon.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Korrektse valimi võtmise all peame siinkohal silmas eelkõige juhuvalikut. Kõikidel populatsiooni liikmetel/elementidel peab olema võrdne võimalus valimisse sattuda. Kui üldpopulatsiooniks on Eesti elanikkond, aga valimisse võtaksime ainult Tallinna elanikud, siis antud valimi põhjal tehtavad järeldused ei oleks kuidagi üldistatavad kõigile Eesti elanikele, vaid ikkagi ainult tallinnlastele. Lisaks juhuvalimile on veel terve rida spetsiifilisemaid valimidisaine (stratifitseeritud valim, klastervalim jne) mida me hetkel ei käsitle. Kuid tuleb meeles pidada, et keerulisemate valimidisainide puhul tuleb hilisemas analüüsis ja järelduste tegemise käigus valimi moodustamise loogikat arvesse võtta.<a href="2-lineaarne-regressioon.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Ka <code>summary()</code> ei anna välja kogu mudeliobjektis sisalduvat infot. Et näha mida mudeliobjekt veel sisaldab, võib kasutada <code>str(mudeliobjekt)</code> käsku.<a href="2-lineaarne-regressioon.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p><span class="math inline">\((t^{*}_{(n-2)})^2=F^{*}_{(1,n-2)}\)</span><a href="2-lineaarne-regressioon.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Sellist mudelit nimetatakse ka ANOVA-ks või täpsemlat One-Way ANOVA-ks (kuna tegemist on ainult ühe kategoriaalse sõltumatu muutujaga)<a href="2-lineaarne-regressioon.html#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="1-sissejuhatus-r-i.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3-logistiline-regressioon.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
